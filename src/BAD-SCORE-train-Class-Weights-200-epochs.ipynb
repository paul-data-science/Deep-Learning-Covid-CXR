{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1489 non-validated image filenames belonging to 2 classes.\n",
      "Found 146 non-validated image filenames belonging to 2 classes.\n",
      "Found 182 non-validated image filenames belonging to 2 classes.\n",
      "Class weights:  {0: 26.589285714285715, 1: 0.07643737166324435}\n",
      "Training distribution:  ['Class COVID-19: 28. ', 'Class non-COVID-19: 1461. ']\n",
      "MODEL CONFIG:  {'KERNEL_SIZE': '(3,3)', 'STRIDES': '(1,1)', 'INIT_FILTERS': 16, 'FILTER_EXP_BASE': 3, 'MAXPOOL_SIZE': '(2,2)', 'CONV_BLOCKS': 3, 'NODES_DENSE0': 128, 'LR': 1e-05, 'OPTIMIZER': 'adam', 'DROPOUT': 0.4, 'L2_LAMBDA': 0.0001}\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv0_0 (Conv2D)                (None, 224, 224, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 224, 224, 16) 64          conv0_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 224, 224, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv0_1 (Conv2D)                (None, 224, 224, 16) 2320        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concat0 (Concatenate)           (None, 224, 224, 19) 0           conv0_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 224, 224, 19) 76          concat0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 224, 224, 19) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 112, 112, 19) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1_0 (Conv2D)                (None, 112, 112, 48) 8256        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 112, 112, 48) 192         conv1_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 112, 112, 48) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1 (Conv2D)                (None, 112, 112, 48) 20784       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concat1 (Concatenate)           (None, 112, 112, 67) 0           conv1_1[0][0]                    \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 112, 112, 67) 268         concat1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 112, 112, 67) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 67)   0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_0 (Conv2D)                (None, 56, 56, 144)  86976       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 144)  576         conv2_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 56, 56, 144)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1 (Conv2D)                (None, 56, 56, 144)  186768      leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concat2 (Concatenate)           (None, 56, 56, 211)  0           conv2_1[0][0]                    \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 211)  844         concat2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 56, 56, 211)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 211)  0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 165424)       0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 165424)       0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          21174400    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            258         leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Activation)             (None, 2)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,482,230\n",
      "Trainable params: 21,481,220\n",
      "Non-trainable params: 1,010\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/200\n",
      " 1/47 [..............................] - ETA: 0s - loss: 512.2767 - accuracy: 0.0312 - precision: 0.0312 - recall: 1.0000 - auc: 0.0342 - f1score: 0.0606WARNING:tensorflow:From C:\\Users\\PaulDS3\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "47/47 [==============================] - 54s 1s/step - loss: 501.7941 - accuracy: 0.3721 - precision: 0.0231 - recall: 0.7857 - auc: 0.3341 - f1score: 0.0449 - val_loss: 431.7567 - val_accuracy: 0.4932 - val_precision: 0.0390 - val_recall: 1.0000 - val_auc: 0.4998 - val_f1score: 0.0750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "47/47 [==============================] - 53s 1s/step - loss: 467.1731 - accuracy: 0.1793 - precision: 0.0209 - recall: 0.9286 - auc: 0.1169 - f1score: 0.0408 - val_loss: 359.8889 - val_accuracy: 0.1096 - val_precision: 0.0226 - val_recall: 1.0000 - val_auc: 0.0638 - val_f1score: 0.0441\n",
      "Epoch 3/200\n",
      "47/47 [==============================] - 53s 1s/step - loss: 439.3719 - accuracy: 0.2424 - precision: 0.0209 - recall: 0.8571 - auc: 0.1964 - f1score: 0.0408 - val_loss: 339.2943 - val_accuracy: 0.0822 - val_precision: 0.0219 - val_recall: 1.0000 - val_auc: 0.0450 - val_f1score: 0.0429\n",
      "Epoch 4/200\n",
      "47/47 [==============================] - 53s 1s/step - loss: 416.5914 - accuracy: 0.2465 - precision: 0.0227 - recall: 0.9286 - auc: 0.1902 - f1score: 0.0443 - val_loss: 331.0986 - val_accuracy: 0.1164 - val_precision: 0.0227 - val_recall: 1.0000 - val_auc: 0.0877 - val_f1score: 0.0444\n",
      "Epoch 5/200\n",
      "47/47 [==============================] - 53s 1s/step - loss: 397.1238 - accuracy: 0.5057 - precision: 0.0342 - recall: 0.9286 - auc: 0.5013 - f1score: 0.0660 - val_loss: 325.7176 - val_accuracy: 0.5342 - val_precision: 0.0423 - val_recall: 1.0000 - val_auc: 0.5168 - val_f1score: 0.0811\n",
      "Epoch 6/200\n",
      "47/47 [==============================] - 53s 1s/step - loss: 380.8140 - accuracy: 0.4439 - precision: 0.0294 - recall: 0.8929 - auc: 0.4213 - f1score: 0.0569 - val_loss: 333.7687 - val_accuracy: 0.0548 - val_precision: 0.0213 - val_recall: 1.0000 - val_auc: 0.0281 - val_f1score: 0.0417\n",
      "Epoch 7/200\n",
      "47/47 [==============================] - 53s 1s/step - loss: 366.3513 - accuracy: 0.3398 - precision: 0.0258 - recall: 0.9286 - auc: 0.3104 - f1score: 0.0502 - val_loss: 331.8340 - val_accuracy: 0.2055 - val_precision: 0.0252 - val_recall: 1.0000 - val_auc: 0.1756 - val_f1score: 0.0492\n",
      "Epoch 8/200\n",
      "47/47 [==============================] - 53s 1s/step - loss: 354.1273 - accuracy: 0.3962 - precision: 0.0282 - recall: 0.9286 - auc: 0.3585 - f1score: 0.0547 - val_loss: 331.0715 - val_accuracy: 0.5205 - val_precision: 0.0411 - val_recall: 1.0000 - val_auc: 0.5021 - val_f1score: 0.0789\n",
      "Epoch 9/200\n",
      "47/47 [==============================] - 53s 1s/step - loss: 342.7410 - accuracy: 0.6575 - precision: 0.0487 - recall: 0.9286 - auc: 0.7036 - f1score: 0.0925 - val_loss: 334.3981 - val_accuracy: 0.1986 - val_precision: 0.0250 - val_recall: 1.0000 - val_auc: 0.1486 - val_f1score: 0.0488\n",
      "Epoch 10/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 332.3952 - accuracy: 0.4580 - precision: 0.0324 - recall: 0.9643 - auc: 0.4395 - f1score: 0.0627 - val_loss: 328.4869 - val_accuracy: 0.6301 - val_precision: 0.0526 - val_recall: 1.0000 - val_auc: 0.6190 - val_f1score: 0.1000\n",
      "Epoch 11/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 323.4612 - accuracy: 0.5823 - precision: 0.0402 - recall: 0.9286 - auc: 0.6205 - f1score: 0.0772 - val_loss: 324.5555 - val_accuracy: 0.6918 - val_precision: 0.0625 - val_recall: 1.0000 - val_auc: 0.7591 - val_f1score: 0.1176\n",
      "Epoch 12/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 315.4515 - accuracy: 0.3566 - precision: 0.0255 - recall: 0.8929 - auc: 0.3188 - f1score: 0.0496 - val_loss: 321.0738 - val_accuracy: 0.7192 - val_precision: 0.0682 - val_recall: 1.0000 - val_auc: 0.7590 - val_f1score: 0.1277\n",
      "Epoch 13/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 307.5330 - accuracy: 0.6702 - precision: 0.0505 - recall: 0.9286 - auc: 0.7232 - f1score: 0.0958 - val_loss: 318.2260 - val_accuracy: 0.4863 - val_precision: 0.0385 - val_recall: 1.0000 - val_auc: 0.4513 - val_f1score: 0.0741\n",
      "Epoch 14/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 300.4687 - accuracy: 0.6253 - precision: 0.0462 - recall: 0.9643 - auc: 0.6703 - f1score: 0.0882 - val_loss: 316.3758 - val_accuracy: 0.1849 - val_precision: 0.0246 - val_recall: 1.0000 - val_auc: 0.1238 - val_f1score: 0.0480\n",
      "Epoch 15/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 293.7668 - accuracy: 0.6481 - precision: 0.0507 - recall: 1.0000 - auc: 0.6970 - f1score: 0.0966 - val_loss: 306.2274 - val_accuracy: 0.6301 - val_precision: 0.0526 - val_recall: 1.0000 - val_auc: 0.6236 - val_f1score: 0.1000\n",
      "Epoch 16/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 287.5271 - accuracy: 0.6891 - precision: 0.0534 - recall: 0.9286 - auc: 0.7402 - f1score: 0.1010 - val_loss: 315.7250 - val_accuracy: 0.0548 - val_precision: 0.0213 - val_recall: 1.0000 - val_auc: 0.0511 - val_f1score: 0.0417\n",
      "Epoch 17/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 282.6030 - accuracy: 0.3418 - precision: 0.0259 - recall: 0.9286 - auc: 0.3043 - f1score: 0.0504 - val_loss: 301.3933 - val_accuracy: 0.1781 - val_precision: 0.0244 - val_recall: 1.0000 - val_auc: 0.1223 - val_f1score: 0.0476\n",
      "Epoch 18/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 276.8765 - accuracy: 0.5668 - precision: 0.0402 - recall: 0.9643 - auc: 0.6051 - f1score: 0.0773 - val_loss: 291.6198 - val_accuracy: 0.5959 - val_precision: 0.0484 - val_recall: 1.0000 - val_auc: 0.6058 - val_f1score: 0.0923\n",
      "Epoch 19/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 271.7332 - accuracy: 0.7609 - precision: 0.0707 - recall: 0.9643 - auc: 0.8409 - f1score: 0.1317 - val_loss: 291.2488 - val_accuracy: 0.2397 - val_precision: 0.0263 - val_recall: 1.0000 - val_auc: 0.1732 - val_f1score: 0.0513\n",
      "Epoch 20/200\n",
      "47/47 [==============================] - 59s 1s/step - loss: 267.0960 - accuracy: 0.6488 - precision: 0.0492 - recall: 0.9643 - auc: 0.6950 - f1score: 0.0936 - val_loss: 281.7758 - val_accuracy: 0.7123 - val_precision: 0.0667 - val_recall: 1.0000 - val_auc: 0.7736 - val_f1score: 0.1250\n",
      "Epoch 21/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 262.5606 - accuracy: 0.6535 - precision: 0.0498 - recall: 0.9643 - auc: 0.6796 - f1score: 0.0947 - val_loss: 285.0161 - val_accuracy: 0.1918 - val_precision: 0.0248 - val_recall: 1.0000 - val_auc: 0.1389 - val_f1score: 0.0484\n",
      "Epoch 22/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 258.0934 - accuracy: 0.7159 - precision: 0.0601 - recall: 0.9643 - auc: 0.7851 - f1score: 0.1132 - val_loss: 273.5408 - val_accuracy: 0.7466 - val_precision: 0.0750 - val_recall: 1.0000 - val_auc: 0.8018 - val_f1score: 0.1395\n",
      "Epoch 23/200\n",
      "47/47 [==============================] - 58s 1s/step - loss: 253.9104 - accuracy: 0.7858 - precision: 0.0807 - recall: 1.0000 - auc: 0.8697 - f1score: 0.1493 - val_loss: 270.6913 - val_accuracy: 0.6233 - val_precision: 0.0517 - val_recall: 1.0000 - val_auc: 0.6659 - val_f1score: 0.0984\n",
      "Epoch 24/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 250.5251 - accuracy: 0.6044 - precision: 0.0424 - recall: 0.9286 - auc: 0.6184 - f1score: 0.0811 - val_loss: 268.0847 - val_accuracy: 0.5205 - val_precision: 0.0411 - val_recall: 1.0000 - val_auc: 0.5037 - val_f1score: 0.0789\n",
      "Epoch 25/200\n",
      "47/47 [==============================] - 58s 1s/step - loss: 246.4420 - accuracy: 0.5903 - precision: 0.0425 - recall: 0.9643 - auc: 0.6300 - f1score: 0.0813 - val_loss: 264.6087 - val_accuracy: 0.5822 - val_precision: 0.0469 - val_recall: 1.0000 - val_auc: 0.5621 - val_f1score: 0.0896\n",
      "Epoch 26/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 243.0033 - accuracy: 0.6561 - precision: 0.0485 - recall: 0.9286 - auc: 0.7017 - f1score: 0.0922 - val_loss: 266.6950 - val_accuracy: 0.2055 - val_precision: 0.0252 - val_recall: 1.0000 - val_auc: 0.1480 - val_f1score: 0.0492\n",
      "Epoch 27/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 239.5176 - accuracy: 0.7179 - precision: 0.0625 - recall: 1.0000 - auc: 0.7758 - f1score: 0.1176 - val_loss: 257.6086 - val_accuracy: 0.5479 - val_precision: 0.0435 - val_recall: 1.0000 - val_auc: 0.5603 - val_f1score: 0.0833\n",
      "Epoch 28/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 236.1044 - accuracy: 0.6897 - precision: 0.0553 - recall: 0.9643 - auc: 0.7454 - f1score: 0.1047 - val_loss: 255.5902 - val_accuracy: 0.4658 - val_precision: 0.0370 - val_recall: 1.0000 - val_auc: 0.4559 - val_f1score: 0.0714\n",
      "Epoch 29/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 233.2058 - accuracy: 0.5749 - precision: 0.0410 - recall: 0.9643 - auc: 0.5830 - f1score: 0.0786 - val_loss: 251.4623 - val_accuracy: 0.5890 - val_precision: 0.0476 - val_recall: 1.0000 - val_auc: 0.6064 - val_f1score: 0.0909\n",
      "Epoch 30/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 230.1763 - accuracy: 0.5870 - precision: 0.0407 - recall: 0.9286 - auc: 0.6126 - f1score: 0.0780 - val_loss: 250.6744 - val_accuracy: 0.3630 - val_precision: 0.0312 - val_recall: 1.0000 - val_auc: 0.3376 - val_f1score: 0.0606\n",
      "Epoch 31/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 227.1384 - accuracy: 0.6568 - precision: 0.0486 - recall: 0.9286 - auc: 0.7131 - f1score: 0.0924 - val_loss: 248.2576 - val_accuracy: 0.3562 - val_precision: 0.0309 - val_recall: 1.0000 - val_auc: 0.3139 - val_f1score: 0.0600\n",
      "Epoch 32/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 224.2292 - accuracy: 0.6514 - precision: 0.0495 - recall: 0.9643 - auc: 0.6886 - f1score: 0.0942 - val_loss: 249.0699 - val_accuracy: 0.1781 - val_precision: 0.0244 - val_recall: 1.0000 - val_auc: 0.1421 - val_f1score: 0.0476\n",
      "Epoch 33/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 221.7078 - accuracy: 0.6206 - precision: 0.0457 - recall: 0.9643 - auc: 0.6581 - f1score: 0.0872 - val_loss: 245.5281 - val_accuracy: 0.1712 - val_precision: 0.0242 - val_recall: 1.0000 - val_auc: 0.1397 - val_f1score: 0.0472\n",
      "Epoch 34/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 218.6971 - accuracy: 0.7293 - precision: 0.0629 - recall: 0.9643 - auc: 0.8005 - f1score: 0.1182 - val_loss: 237.8851 - val_accuracy: 0.5205 - val_precision: 0.0411 - val_recall: 1.0000 - val_auc: 0.4991 - val_f1score: 0.0789\n",
      "Epoch 35/200\n",
      "47/47 [==============================] - 58s 1s/step - loss: 215.9450 - accuracy: 0.8240 - precision: 0.0966 - recall: 1.0000 - auc: 0.8964 - f1score: 0.1761 - val_loss: 232.7881 - val_accuracy: 0.8014 - val_precision: 0.0938 - val_recall: 1.0000 - val_auc: 0.8661 - val_f1score: 0.1714\n",
      "Epoch 36/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 213.8686 - accuracy: 0.6340 - precision: 0.0457 - recall: 0.9286 - auc: 0.6700 - f1score: 0.0871 - val_loss: 236.2693 - val_accuracy: 0.2740 - val_precision: 0.0275 - val_recall: 1.0000 - val_auc: 0.2771 - val_f1score: 0.0536\n",
      "Epoch 37/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 211.6208 - accuracy: 0.5440 - precision: 0.0383 - recall: 0.9643 - auc: 0.5426 - f1score: 0.0737 - val_loss: 232.7583 - val_accuracy: 0.3219 - val_precision: 0.0294 - val_recall: 1.0000 - val_auc: 0.3021 - val_f1score: 0.0571\n",
      "Epoch 38/200\n",
      "47/47 [==============================] - 58s 1s/step - loss: 208.9101 - accuracy: 0.6642 - precision: 0.0513 - recall: 0.9643 - auc: 0.7071 - f1score: 0.0975 - val_loss: 232.8433 - val_accuracy: 0.2260 - val_precision: 0.0259 - val_recall: 1.0000 - val_auc: 0.2005 - val_f1score: 0.0504\n",
      "Epoch 39/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 206.2967 - accuracy: 0.7287 - precision: 0.0648 - recall: 1.0000 - auc: 0.7746 - f1score: 0.1217 - val_loss: 225.6062 - val_accuracy: 0.6370 - val_precision: 0.0536 - val_recall: 1.0000 - val_auc: 0.6118 - val_f1score: 0.1017\n",
      "Epoch 40/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 203.9550 - accuracy: 0.7280 - precision: 0.0647 - recall: 1.0000 - auc: 0.7804 - f1score: 0.1215 - val_loss: 221.1183 - val_accuracy: 0.8014 - val_precision: 0.0667 - val_recall: 0.6667 - val_auc: 0.8574 - val_f1score: 0.1212\n",
      "Epoch 41/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 201.6389 - accuracy: 0.8717 - precision: 0.1279 - recall: 1.0000 - auc: 0.9350 - f1score: 0.2267 - val_loss: 220.4636 - val_accuracy: 0.6507 - val_precision: 0.0556 - val_recall: 1.0000 - val_auc: 0.6965 - val_f1score: 0.1053\n",
      "Epoch 42/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 199.7209 - accuracy: 0.6944 - precision: 0.0561 - recall: 0.9643 - auc: 0.7379 - f1score: 0.1061 - val_loss: 217.7889 - val_accuracy: 0.6986 - val_precision: 0.0638 - val_recall: 1.0000 - val_auc: 0.7836 - val_f1score: 0.1200\n",
      "Epoch 43/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 197.6355 - accuracy: 0.6716 - precision: 0.0507 - recall: 0.9286 - auc: 0.7195 - f1score: 0.0961 - val_loss: 224.6714 - val_accuracy: 0.1370 - val_precision: 0.0233 - val_recall: 1.0000 - val_auc: 0.1123 - val_f1score: 0.0455\n",
      "Epoch 44/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 195.4099 - accuracy: 0.7119 - precision: 0.0613 - recall: 1.0000 - auc: 0.7722 - f1score: 0.1155 - val_loss: 213.1714 - val_accuracy: 0.6849 - val_precision: 0.0612 - val_recall: 1.0000 - val_auc: 0.7581 - val_f1score: 0.1154\n",
      "Epoch 45/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 193.2924 - accuracy: 0.8415 - precision: 0.1061 - recall: 1.0000 - auc: 0.9001 - f1score: 0.1918 - val_loss: 211.4323 - val_accuracy: 0.6712 - val_precision: 0.0588 - val_recall: 1.0000 - val_auc: 0.7230 - val_f1score: 0.1111\n",
      "Epoch 46/200\n",
      "47/47 [==============================] - 58s 1s/step - loss: 191.4106 - accuracy: 0.7918 - precision: 0.0804 - recall: 0.9643 - auc: 0.8527 - f1score: 0.1484 - val_loss: 221.6940 - val_accuracy: 0.1164 - val_precision: 0.0227 - val_recall: 1.0000 - val_auc: 0.1065 - val_f1score: 0.0444\n",
      "Epoch 47/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 189.8418 - accuracy: 0.5326 - precision: 0.0374 - recall: 0.9643 - auc: 0.5414 - f1score: 0.0720 - val_loss: 212.8736 - val_accuracy: 0.2329 - val_precision: 0.0261 - val_recall: 1.0000 - val_auc: 0.2147 - val_f1score: 0.0508\n",
      "Epoch 48/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 187.4874 - accuracy: 0.7683 - precision: 0.0728 - recall: 0.9643 - auc: 0.8291 - f1score: 0.1353 - val_loss: 207.1153 - val_accuracy: 0.5411 - val_precision: 0.0429 - val_recall: 1.0000 - val_auc: 0.5144 - val_f1score: 0.0822\n",
      "Epoch 49/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 185.5770 - accuracy: 0.7300 - precision: 0.0651 - recall: 1.0000 - auc: 0.7929 - f1score: 0.1223 - val_loss: 202.9255 - val_accuracy: 0.7329 - val_precision: 0.0500 - val_recall: 0.6667 - val_auc: 0.8321 - val_f1score: 0.0930\n",
      "Epoch 50/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 183.6314 - accuracy: 0.8267 - precision: 0.0951 - recall: 0.9643 - auc: 0.8825 - f1score: 0.1731 - val_loss: 200.0196 - val_accuracy: 0.8767 - val_precision: 0.1053 - val_recall: 0.6667 - val_auc: 0.9498 - val_f1score: 0.1818\n",
      "Epoch 51/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 181.9449 - accuracy: 0.8536 - precision: 0.1107 - recall: 0.9643 - auc: 0.9158 - f1score: 0.1985 - val_loss: 199.0400 - val_accuracy: 0.7466 - val_precision: 0.0526 - val_recall: 0.6667 - val_auc: 0.8197 - val_f1score: 0.0976\n",
      "Epoch 52/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 180.0935 - accuracy: 0.8200 - precision: 0.0946 - recall: 1.0000 - auc: 0.8795 - f1score: 0.1728 - val_loss: 196.3538 - val_accuracy: 0.9041 - val_precision: 0.1333 - val_recall: 0.6667 - val_auc: 0.9685 - val_f1score: 0.2222\n",
      "Epoch 53/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 178.5963 - accuracy: 0.6373 - precision: 0.0477 - recall: 0.9643 - auc: 0.6782 - f1score: 0.0909 - val_loss: 221.5693 - val_accuracy: 0.0479 - val_precision: 0.0211 - val_recall: 1.0000 - val_auc: 0.0426 - val_f1score: 0.0414\n",
      "Epoch 54/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 176.6931 - accuracy: 0.7085 - precision: 0.0606 - recall: 1.0000 - auc: 0.7360 - f1score: 0.1143 - val_loss: 194.3062 - val_accuracy: 0.7329 - val_precision: 0.0714 - val_recall: 1.0000 - val_auc: 0.7772 - val_f1score: 0.1333\n",
      "Epoch 55/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 174.8592 - accuracy: 0.8475 - precision: 0.1067 - recall: 0.9643 - auc: 0.8950 - f1score: 0.1922 - val_loss: 202.5414 - val_accuracy: 0.1438 - val_precision: 0.0234 - val_recall: 1.0000 - val_auc: 0.1330 - val_f1score: 0.0458\n",
      "Epoch 56/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 54s 1s/step - loss: 174.2622 - accuracy: 0.4486 - precision: 0.0308 - recall: 0.9286 - auc: 0.4359 - f1score: 0.0596 - val_loss: 207.7994 - val_accuracy: 0.0685 - val_precision: 0.0216 - val_recall: 1.0000 - val_auc: 0.0452 - val_f1score: 0.0423\n",
      "Epoch 57/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 171.8729 - accuracy: 0.5527 - precision: 0.0390 - recall: 0.9643 - auc: 0.5635 - f1score: 0.0750 - val_loss: 191.1379 - val_accuracy: 0.6096 - val_precision: 0.0500 - val_recall: 1.0000 - val_auc: 0.6045 - val_f1score: 0.0952\n",
      "Epoch 58/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 170.0652 - accuracy: 0.8200 - precision: 0.0918 - recall: 0.9643 - auc: 0.8883 - f1score: 0.1677 - val_loss: 188.1496 - val_accuracy: 0.6918 - val_precision: 0.0625 - val_recall: 1.0000 - val_auc: 0.7611 - val_f1score: 0.1176\n",
      "Epoch 59/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 168.2704 - accuracy: 0.8811 - precision: 0.1366 - recall: 1.0000 - auc: 0.9382 - f1score: 0.2403 - val_loss: 185.9140 - val_accuracy: 0.7466 - val_precision: 0.0750 - val_recall: 1.0000 - val_auc: 0.8206 - val_f1score: 0.1395\n",
      "Epoch 60/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 166.9393 - accuracy: 0.7032 - precision: 0.0577 - recall: 0.9643 - auc: 0.7414 - f1score: 0.1089 - val_loss: 186.3410 - val_accuracy: 0.6164 - val_precision: 0.0508 - val_recall: 1.0000 - val_auc: 0.6080 - val_f1score: 0.0968\n",
      "Epoch 61/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 165.2892 - accuracy: 0.8052 - precision: 0.0854 - recall: 0.9643 - auc: 0.8630 - f1score: 0.1570 - val_loss: 182.3887 - val_accuracy: 0.7740 - val_precision: 0.0588 - val_recall: 0.6667 - val_auc: 0.8360 - val_f1score: 0.1081\n",
      "Epoch 62/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 163.9289 - accuracy: 0.7569 - precision: 0.0674 - recall: 0.9286 - auc: 0.8182 - f1score: 0.1256 - val_loss: 181.4237 - val_accuracy: 0.7192 - val_precision: 0.0476 - val_recall: 0.6667 - val_auc: 0.7933 - val_f1score: 0.0889\n",
      "Epoch 63/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 162.5828 - accuracy: 0.6649 - precision: 0.0514 - recall: 0.9643 - auc: 0.6988 - f1score: 0.0976 - val_loss: 184.9055 - val_accuracy: 0.3767 - val_precision: 0.0319 - val_recall: 1.0000 - val_auc: 0.3260 - val_f1score: 0.0619\n",
      "Epoch 64/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 161.3995 - accuracy: 0.6011 - precision: 0.0421 - recall: 0.9286 - auc: 0.6032 - f1score: 0.0805 - val_loss: 205.0617 - val_accuracy: 0.0479 - val_precision: 0.0211 - val_recall: 1.0000 - val_auc: 0.0358 - val_f1score: 0.0414\n",
      "Epoch 65/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 159.5655 - accuracy: 0.6273 - precision: 0.0480 - recall: 1.0000 - auc: 0.6659 - f1score: 0.0917 - val_loss: 180.6436 - val_accuracy: 0.4521 - val_precision: 0.0361 - val_recall: 1.0000 - val_auc: 0.4206 - val_f1score: 0.0698\n",
      "Epoch 66/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 158.2217 - accuracy: 0.6152 - precision: 0.0451 - recall: 0.9643 - auc: 0.6451 - f1score: 0.0861 - val_loss: 176.2354 - val_accuracy: 0.6507 - val_precision: 0.0556 - val_recall: 1.0000 - val_auc: 0.6926 - val_f1score: 0.1053\n",
      "Epoch 67/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 156.6387 - accuracy: 0.6844 - precision: 0.0544 - recall: 0.9643 - auc: 0.7242 - f1score: 0.1031 - val_loss: 173.8389 - val_accuracy: 0.7260 - val_precision: 0.0488 - val_recall: 0.6667 - val_auc: 0.8004 - val_f1score: 0.0909\n",
      "Epoch 68/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 154.9917 - accuracy: 0.9214 - precision: 0.1931 - recall: 1.0000 - auc: 0.9715 - f1score: 0.3237 - val_loss: 172.1805 - val_accuracy: 0.7671 - val_precision: 0.0571 - val_recall: 0.6667 - val_auc: 0.8504 - val_f1score: 0.1053\n",
      "Epoch 69/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 153.7780 - accuracy: 0.6924 - precision: 0.0539 - recall: 0.9286 - auc: 0.7401 - f1score: 0.1020 - val_loss: 174.4970 - val_accuracy: 0.5137 - val_precision: 0.0405 - val_recall: 1.0000 - val_auc: 0.5057 - val_f1score: 0.0779\n",
      "Epoch 70/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 152.4383 - accuracy: 0.7381 - precision: 0.0649 - recall: 0.9643 - auc: 0.7964 - f1score: 0.1216 - val_loss: 174.7304 - val_accuracy: 0.4384 - val_precision: 0.0353 - val_recall: 1.0000 - val_auc: 0.3840 - val_f1score: 0.0682\n",
      "Epoch 71/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 151.0145 - accuracy: 0.8234 - precision: 0.0962 - recall: 1.0000 - auc: 0.8893 - f1score: 0.1755 - val_loss: 169.1282 - val_accuracy: 0.6781 - val_precision: 0.0600 - val_recall: 1.0000 - val_auc: 0.7052 - val_f1score: 0.1132\n",
      "Epoch 72/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 149.6171 - accuracy: 0.8798 - precision: 0.1353 - recall: 1.0000 - auc: 0.9371 - f1score: 0.2383 - val_loss: 168.7231 - val_accuracy: 0.5959 - val_precision: 0.0484 - val_recall: 1.0000 - val_auc: 0.6189 - val_f1score: 0.0923\n",
      "Epoch 73/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 148.5107 - accuracy: 0.7253 - precision: 0.0621 - recall: 0.9643 - auc: 0.7709 - f1score: 0.1166 - val_loss: 173.5498 - val_accuracy: 0.2192 - val_precision: 0.0256 - val_recall: 1.0000 - val_auc: 0.2034 - val_f1score: 0.0500\n",
      "Epoch 74/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 147.3001 - accuracy: 0.6427 - precision: 0.0484 - recall: 0.9643 - auc: 0.6869 - f1score: 0.0922 - val_loss: 167.9604 - val_accuracy: 0.5137 - val_precision: 0.0405 - val_recall: 1.0000 - val_auc: 0.4543 - val_f1score: 0.0779\n",
      "Epoch 75/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 145.9804 - accuracy: 0.6259 - precision: 0.0432 - recall: 0.8929 - auc: 0.6716 - f1score: 0.0824 - val_loss: 173.8618 - val_accuracy: 0.1233 - val_precision: 0.0229 - val_recall: 1.0000 - val_auc: 0.1190 - val_f1score: 0.0448\n",
      "Epoch 76/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 144.7908 - accuracy: 0.5480 - precision: 0.0399 - recall: 1.0000 - auc: 0.5604 - f1score: 0.0768 - val_loss: 163.8423 - val_accuracy: 0.5548 - val_precision: 0.0441 - val_recall: 1.0000 - val_auc: 0.5642 - val_f1score: 0.0845\n",
      "Epoch 77/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 143.1480 - accuracy: 0.7837 - precision: 0.0800 - recall: 1.0000 - auc: 0.8403 - f1score: 0.1481 - val_loss: 161.5437 - val_accuracy: 0.6575 - val_precision: 0.0566 - val_recall: 1.0000 - val_auc: 0.6838 - val_f1score: 0.1071\n",
      "Epoch 78/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 141.7432 - accuracy: 0.8919 - precision: 0.1481 - recall: 1.0000 - auc: 0.9397 - f1score: 0.2581 - val_loss: 158.6726 - val_accuracy: 0.7534 - val_precision: 0.0286 - val_recall: 0.3333 - val_auc: 0.8451 - val_f1score: 0.0526\n",
      "Epoch 79/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 140.6390 - accuracy: 0.7629 - precision: 0.0712 - recall: 0.9643 - auc: 0.8194 - f1score: 0.1327 - val_loss: 156.7758 - val_accuracy: 0.9247 - val_precision: 0.1000 - val_recall: 0.3333 - val_auc: 0.9658 - val_f1score: 0.1538\n",
      "Epoch 80/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 139.6301 - accuracy: 0.7260 - precision: 0.0602 - recall: 0.9286 - auc: 0.7608 - f1score: 0.1130 - val_loss: 163.2147 - val_accuracy: 0.3219 - val_precision: 0.0294 - val_recall: 1.0000 - val_auc: 0.2865 - val_f1score: 0.0571\n",
      "Epoch 81/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 138.3253 - accuracy: 0.7280 - precision: 0.0626 - recall: 0.9643 - auc: 0.7829 - f1score: 0.1176 - val_loss: 159.5940 - val_accuracy: 0.4247 - val_precision: 0.0345 - val_recall: 1.0000 - val_auc: 0.4027 - val_f1score: 0.0667\n",
      "Epoch 82/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 137.0488 - accuracy: 0.7891 - precision: 0.0794 - recall: 0.9643 - auc: 0.8533 - f1score: 0.1467 - val_loss: 153.5345 - val_accuracy: 0.7945 - val_precision: 0.0345 - val_recall: 0.3333 - val_auc: 0.9030 - val_f1score: 0.0625\n",
      "Epoch 83/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 135.7835 - accuracy: 0.9281 - precision: 0.2074 - recall: 1.0000 - auc: 0.9751 - f1score: 0.3436 - val_loss: 152.3289 - val_accuracy: 0.8356 - val_precision: 0.0435 - val_recall: 0.3333 - val_auc: 0.9246 - val_f1score: 0.0769\n",
      "Epoch 84/200\n",
      "47/47 [==============================] - 53s 1s/step - loss: 135.1417 - accuracy: 0.6635 - precision: 0.0478 - recall: 0.8929 - auc: 0.6852 - f1score: 0.0907 - val_loss: 164.1023 - val_accuracy: 0.1849 - val_precision: 0.0246 - val_recall: 1.0000 - val_auc: 0.1401 - val_f1score: 0.0480\n",
      "Epoch 85/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 133.9049 - accuracy: 0.6394 - precision: 0.0496 - recall: 1.0000 - auc: 0.6578 - f1score: 0.0944 - val_loss: 151.0443 - val_accuracy: 0.7260 - val_precision: 0.0698 - val_recall: 1.0000 - val_auc: 0.7914 - val_f1score: 0.1304\n",
      "Epoch 86/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 132.4679 - accuracy: 0.8475 - precision: 0.1067 - recall: 0.9643 - auc: 0.9064 - f1score: 0.1922 - val_loss: 155.9712 - val_accuracy: 0.3288 - val_precision: 0.0297 - val_recall: 1.0000 - val_auc: 0.2984 - val_f1score: 0.0577\n",
      "Epoch 87/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 131.5871 - accuracy: 0.6132 - precision: 0.0449 - recall: 0.9643 - auc: 0.6297 - f1score: 0.0857 - val_loss: 160.9812 - val_accuracy: 0.1438 - val_precision: 0.0234 - val_recall: 1.0000 - val_auc: 0.1087 - val_f1score: 0.0458\n",
      "Epoch 88/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 130.3911 - accuracy: 0.6662 - precision: 0.0516 - recall: 0.9643 - auc: 0.7077 - f1score: 0.0980 - val_loss: 147.5208 - val_accuracy: 0.7123 - val_precision: 0.0667 - val_recall: 1.0000 - val_auc: 0.7750 - val_f1score: 0.1250\n",
      "Epoch 89/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 128.9638 - accuracy: 0.9167 - precision: 0.1842 - recall: 1.0000 - auc: 0.9642 - f1score: 0.3111 - val_loss: 145.7415 - val_accuracy: 0.7808 - val_precision: 0.0323 - val_recall: 0.3333 - val_auc: 0.8445 - val_f1score: 0.0588\n",
      "Epoch 90/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 127.7706 - accuracy: 0.8999 - precision: 0.1582 - recall: 1.0000 - auc: 0.9486 - f1score: 0.2732 - val_loss: 145.1719 - val_accuracy: 0.7260 - val_precision: 0.0488 - val_recall: 0.6667 - val_auc: 0.7974 - val_f1score: 0.0909\n",
      "Epoch 91/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 126.8926 - accuracy: 0.8449 - precision: 0.1081 - recall: 1.0000 - auc: 0.9063 - f1score: 0.1951 - val_loss: 143.2557 - val_accuracy: 0.7945 - val_precision: 0.0345 - val_recall: 0.3333 - val_auc: 0.8942 - val_f1score: 0.0625\n",
      "Epoch 92/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 125.7236 - accuracy: 0.8529 - precision: 0.1134 - recall: 1.0000 - auc: 0.9041 - f1score: 0.2036 - val_loss: 141.4648 - val_accuracy: 0.8904 - val_precision: 0.0667 - val_recall: 0.3333 - val_auc: 0.9581 - val_f1score: 0.1111\n",
      "Epoch 93/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 124.6469 - accuracy: 0.9053 - precision: 0.1657 - recall: 1.0000 - auc: 0.9543 - f1score: 0.2843 - val_loss: 140.3694 - val_accuracy: 0.9110 - val_precision: 0.0833 - val_recall: 0.3333 - val_auc: 0.9635 - val_f1score: 0.1333\n",
      "Epoch 94/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 123.4438 - accuracy: 0.9490 - precision: 0.2692 - recall: 1.0000 - auc: 0.9804 - f1score: 0.4242 - val_loss: 139.6825 - val_accuracy: 0.8699 - val_precision: 0.0556 - val_recall: 0.3333 - val_auc: 0.9367 - val_f1score: 0.0952\n",
      "Epoch 95/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 122.6030 - accuracy: 0.7260 - precision: 0.0622 - recall: 0.9643 - auc: 0.7855 - f1score: 0.1169 - val_loss: 141.9285 - val_accuracy: 0.5548 - val_precision: 0.0441 - val_recall: 1.0000 - val_auc: 0.5602 - val_f1score: 0.0845\n",
      "Epoch 96/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 122.3080 - accuracy: 0.5104 - precision: 0.0345 - recall: 0.9286 - auc: 0.5081 - f1score: 0.0666 - val_loss: 138.0952 - val_accuracy: 0.8014 - val_precision: 0.0357 - val_recall: 0.3333 - val_auc: 0.8742 - val_f1score: 0.0645\n",
      "Epoch 97/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 120.7173 - accuracy: 0.6991 - precision: 0.0551 - recall: 0.9286 - auc: 0.7435 - f1score: 0.1040 - val_loss: 143.2565 - val_accuracy: 0.3356 - val_precision: 0.0300 - val_recall: 1.0000 - val_auc: 0.2934 - val_f1score: 0.0583\n",
      "Epoch 98/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 119.5036 - accuracy: 0.7858 - precision: 0.0807 - recall: 1.0000 - auc: 0.8466 - f1score: 0.1493 - val_loss: 136.4613 - val_accuracy: 0.7123 - val_precision: 0.0465 - val_recall: 0.6667 - val_auc: 0.7731 - val_f1score: 0.0870\n",
      "Epoch 99/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 118.4534 - accuracy: 0.9147 - precision: 0.1806 - recall: 1.0000 - auc: 0.9599 - f1score: 0.3060 - val_loss: 134.7382 - val_accuracy: 0.7671 - val_precision: 0.0303 - val_recall: 0.3333 - val_auc: 0.8640 - val_f1score: 0.0556\n",
      "Epoch 100/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 117.3846 - accuracy: 0.8576 - precision: 0.1134 - recall: 0.9643 - auc: 0.9021 - f1score: 0.2030 - val_loss: 147.8354 - val_accuracy: 0.1438 - val_precision: 0.0234 - val_recall: 1.0000 - val_auc: 0.1285 - val_f1score: 0.0458\n",
      "Epoch 101/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 116.6082 - accuracy: 0.7314 - precision: 0.0634 - recall: 0.9643 - auc: 0.7677 - f1score: 0.1189 - val_loss: 133.0058 - val_accuracy: 0.7466 - val_precision: 0.0526 - val_recall: 0.6667 - val_auc: 0.8024 - val_f1score: 0.0976\n",
      "Epoch 102/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 115.4249 - accuracy: 0.8805 - precision: 0.1359 - recall: 1.0000 - auc: 0.9304 - f1score: 0.2393 - val_loss: 144.0774 - val_accuracy: 0.2055 - val_precision: 0.0252 - val_recall: 1.0000 - val_auc: 0.1638 - val_f1score: 0.0492\n",
      "Epoch 103/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 114.6808 - accuracy: 0.6622 - precision: 0.0510 - recall: 0.9643 - auc: 0.7008 - f1score: 0.0969 - val_loss: 133.1901 - val_accuracy: 0.6096 - val_precision: 0.0500 - val_recall: 1.0000 - val_auc: 0.6143 - val_f1score: 0.0952\n",
      "Epoch 104/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 113.7041 - accuracy: 0.7226 - precision: 0.0615 - recall: 0.9643 - auc: 0.7620 - f1score: 0.1156 - val_loss: 129.3953 - val_accuracy: 0.8219 - val_precision: 0.0400 - val_recall: 0.3333 - val_auc: 0.9057 - val_f1score: 0.0714\n",
      "Epoch 105/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 112.6033 - accuracy: 0.8966 - precision: 0.1538 - recall: 1.0000 - auc: 0.9465 - f1score: 0.2667 - val_loss: 128.3267 - val_accuracy: 0.8288 - val_precision: 0.0417 - val_recall: 0.3333 - val_auc: 0.8957 - val_f1score: 0.0741\n",
      "Epoch 106/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 111.7208 - accuracy: 0.7394 - precision: 0.0652 - recall: 0.9643 - auc: 0.7845 - f1score: 0.1222 - val_loss: 126.8723 - val_accuracy: 0.9247 - val_precision: 0.1000 - val_recall: 0.3333 - val_auc: 0.9625 - val_f1score: 0.1538\n",
      "Epoch 107/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 110.7980 - accuracy: 0.8126 - precision: 0.0885 - recall: 0.9643 - auc: 0.8738 - f1score: 0.1622 - val_loss: 126.9156 - val_accuracy: 0.7466 - val_precision: 0.0526 - val_recall: 0.6667 - val_auc: 0.7804 - val_f1score: 0.0976\n",
      "Epoch 108/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 109.7550 - accuracy: 0.8784 - precision: 0.1340 - recall: 1.0000 - auc: 0.9392 - f1score: 0.2363 - val_loss: 125.2379 - val_accuracy: 0.8151 - val_precision: 0.0385 - val_recall: 0.3333 - val_auc: 0.9174 - val_f1score: 0.0690\n",
      "Epoch 109/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 108.9956 - accuracy: 0.7018 - precision: 0.0574 - recall: 0.9643 - auc: 0.7548 - f1score: 0.1084 - val_loss: 125.3553 - val_accuracy: 0.6986 - val_precision: 0.0444 - val_recall: 0.6667 - val_auc: 0.7630 - val_f1score: 0.0833\n",
      "Epoch 110/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 56s 1s/step - loss: 108.4047 - accuracy: 0.6387 - precision: 0.0463 - recall: 0.9286 - auc: 0.6690 - f1score: 0.0881 - val_loss: 132.4173 - val_accuracy: 0.2055 - val_precision: 0.0252 - val_recall: 1.0000 - val_auc: 0.1616 - val_f1score: 0.0492\n",
      "Epoch 111/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 107.2813 - accuracy: 0.6723 - precision: 0.0543 - recall: 1.0000 - auc: 0.7180 - f1score: 0.1029 - val_loss: 124.0439 - val_accuracy: 0.6233 - val_precision: 0.0357 - val_recall: 0.6667 - val_auc: 0.6721 - val_f1score: 0.0678\n",
      "Epoch 112/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 106.0842 - accuracy: 0.9113 - precision: 0.1750 - recall: 1.0000 - auc: 0.9591 - f1score: 0.2979 - val_loss: 121.5131 - val_accuracy: 0.8493 - val_precision: 0.0476 - val_recall: 0.3333 - val_auc: 0.9345 - val_f1score: 0.0833\n",
      "Epoch 113/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 105.2161 - accuracy: 0.8878 - precision: 0.1436 - recall: 1.0000 - auc: 0.9382 - f1score: 0.2511 - val_loss: 120.7455 - val_accuracy: 0.8014 - val_precision: 0.0357 - val_recall: 0.3333 - val_auc: 0.8937 - val_f1score: 0.0645\n",
      "Epoch 114/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 104.3722 - accuracy: 0.9255 - precision: 0.2014 - recall: 1.0000 - auc: 0.9688 - f1score: 0.3353 - val_loss: 119.6415 - val_accuracy: 0.8630 - val_precision: 0.0526 - val_recall: 0.3333 - val_auc: 0.9399 - val_f1score: 0.0909\n",
      "Epoch 115/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 103.4934 - accuracy: 0.9241 - precision: 0.1986 - recall: 1.0000 - auc: 0.9699 - f1score: 0.3314 - val_loss: 118.7088 - val_accuracy: 0.8699 - val_precision: 0.0556 - val_recall: 0.3333 - val_auc: 0.9359 - val_f1score: 0.0952\n",
      "Epoch 116/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 102.6757 - accuracy: 0.8502 - precision: 0.1116 - recall: 1.0000 - auc: 0.8968 - f1score: 0.2007 - val_loss: 117.5226 - val_accuracy: 0.9384 - val_precision: 0.1250 - val_recall: 0.3333 - val_auc: 0.9728 - val_f1score: 0.1818\n",
      "Epoch 117/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 101.7559 - accuracy: 0.9127 - precision: 0.1772 - recall: 1.0000 - auc: 0.9567 - f1score: 0.3011 - val_loss: 116.8511 - val_accuracy: 0.9110 - val_precision: 0.0833 - val_recall: 0.3333 - val_auc: 0.9607 - val_f1score: 0.1333\n",
      "Epoch 118/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 101.5583 - accuracy: 0.6434 - precision: 0.0485 - recall: 0.9643 - auc: 0.6493 - f1score: 0.0923 - val_loss: 116.2133 - val_accuracy: 0.9110 - val_precision: 0.0833 - val_recall: 0.3333 - val_auc: 0.9456 - val_f1score: 0.1333\n",
      "Epoch 119/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 100.2281 - accuracy: 0.8502 - precision: 0.1084 - recall: 0.9643 - auc: 0.8986 - f1score: 0.1949 - val_loss: 118.1976 - val_accuracy: 0.5685 - val_precision: 0.0455 - val_recall: 1.0000 - val_auc: 0.5911 - val_f1score: 0.0870\n",
      "Epoch 120/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 99.4912 - accuracy: 0.6756 - precision: 0.0530 - recall: 0.9643 - auc: 0.7104 - f1score: 0.1006 - val_loss: 120.5690 - val_accuracy: 0.3425 - val_precision: 0.0303 - val_recall: 1.0000 - val_auc: 0.3334 - val_f1score: 0.0588\n",
      "Epoch 121/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 98.5076 - accuracy: 0.8825 - precision: 0.1379 - recall: 1.0000 - auc: 0.9360 - f1score: 0.2424 - val_loss: 114.7329 - val_accuracy: 0.7466 - val_precision: 0.0526 - val_recall: 0.6667 - val_auc: 0.8015 - val_f1score: 0.0976\n",
      "Epoch 122/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 97.6535 - accuracy: 0.9295 - precision: 0.2105 - recall: 1.0000 - auc: 0.9716 - f1score: 0.3478 - val_loss: 113.2741 - val_accuracy: 0.7603 - val_precision: 0.0294 - val_recall: 0.3333 - val_auc: 0.8570 - val_f1score: 0.0541\n",
      "Epoch 123/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 97.0724 - accuracy: 0.7381 - precision: 0.0649 - recall: 0.9643 - auc: 0.7674 - f1score: 0.1216 - val_loss: 124.4412 - val_accuracy: 0.1438 - val_precision: 0.0234 - val_recall: 1.0000 - val_auc: 0.1189 - val_f1score: 0.0458\n",
      "Epoch 124/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 96.2846 - accuracy: 0.8026 - precision: 0.0870 - recall: 1.0000 - auc: 0.8613 - f1score: 0.1600 - val_loss: 111.9445 - val_accuracy: 0.7397 - val_precision: 0.0270 - val_recall: 0.3333 - val_auc: 0.7868 - val_f1score: 0.0500\n",
      "Epoch 125/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 95.2008 - accuracy: 0.8704 - precision: 0.1267 - recall: 1.0000 - auc: 0.9298 - f1score: 0.2249 - val_loss: 110.4154 - val_accuracy: 0.8836 - val_precision: 0.0625 - val_recall: 0.3333 - val_auc: 0.9361 - val_f1score: 0.1053\n",
      "Epoch 126/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 94.4433 - accuracy: 0.8697 - precision: 0.1261 - recall: 1.0000 - auc: 0.9247 - f1score: 0.2240 - val_loss: 109.6427 - val_accuracy: 0.8493 - val_precision: 0.0476 - val_recall: 0.3333 - val_auc: 0.9215 - val_f1score: 0.0833\n",
      "Epoch 127/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 93.6506 - accuracy: 0.9469 - precision: 0.2617 - recall: 1.0000 - auc: 0.9790 - f1score: 0.4148 - val_loss: 108.9888 - val_accuracy: 0.8493 - val_precision: 0.0476 - val_recall: 0.3333 - val_auc: 0.9101 - val_f1score: 0.0833\n",
      "Epoch 128/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 92.9816 - accuracy: 0.8160 - precision: 0.0927 - recall: 1.0000 - auc: 0.8653 - f1score: 0.1697 - val_loss: 108.2337 - val_accuracy: 0.8151 - val_precision: 0.0385 - val_recall: 0.3333 - val_auc: 0.8869 - val_f1score: 0.0690\n",
      "Epoch 129/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 92.2629 - accuracy: 0.7784 - precision: 0.0782 - recall: 1.0000 - auc: 0.8328 - f1score: 0.1451 - val_loss: 106.9659 - val_accuracy: 0.8699 - val_precision: 0.0556 - val_recall: 0.3333 - val_auc: 0.9252 - val_f1score: 0.0952\n",
      "Epoch 130/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 91.7539 - accuracy: 0.7334 - precision: 0.0638 - recall: 0.9643 - auc: 0.7763 - f1score: 0.1197 - val_loss: 106.4726 - val_accuracy: 0.7945 - val_precision: 0.0645 - val_recall: 0.6667 - val_auc: 0.8576 - val_f1score: 0.1176\n",
      "Epoch 131/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 90.6652 - accuracy: 0.8684 - precision: 0.1216 - recall: 0.9643 - auc: 0.9277 - f1score: 0.2160 - val_loss: 105.1628 - val_accuracy: 0.9247 - val_precision: 0.1000 - val_recall: 0.3333 - val_auc: 0.9645 - val_f1score: 0.1538\n",
      "Epoch 132/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 90.0921 - accuracy: 0.7273 - precision: 0.0625 - recall: 0.9643 - auc: 0.7894 - f1score: 0.1174 - val_loss: 108.2782 - val_accuracy: 0.4932 - val_precision: 0.0390 - val_recall: 1.0000 - val_auc: 0.4888 - val_f1score: 0.0750\n",
      "Epoch 133/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 89.2463 - accuracy: 0.8475 - precision: 0.1067 - recall: 0.9643 - auc: 0.9162 - f1score: 0.1922 - val_loss: 103.7834 - val_accuracy: 0.8836 - val_precision: 0.0625 - val_recall: 0.3333 - val_auc: 0.9438 - val_f1score: 0.1053\n",
      "Epoch 134/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 88.8074 - accuracy: 0.7186 - precision: 0.0607 - recall: 0.9643 - auc: 0.7565 - f1score: 0.1142 - val_loss: 103.6072 - val_accuracy: 0.7945 - val_precision: 0.0345 - val_recall: 0.3333 - val_auc: 0.8672 - val_f1score: 0.0625\n",
      "Epoch 135/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 87.7808 - accuracy: 0.8932 - precision: 0.1497 - recall: 1.0000 - auc: 0.9528 - f1score: 0.2605 - val_loss: 102.8388 - val_accuracy: 0.7534 - val_precision: 0.0286 - val_recall: 0.3333 - val_auc: 0.8472 - val_f1score: 0.0526\n",
      "Epoch 136/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 87.1204 - accuracy: 0.8825 - precision: 0.1379 - recall: 1.0000 - auc: 0.9346 - f1score: 0.2424 - val_loss: 101.3026 - val_accuracy: 0.9110 - val_precision: 0.0833 - val_recall: 0.3333 - val_auc: 0.9527 - val_f1score: 0.1333\n",
      "Epoch 137/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 86.3097 - accuracy: 0.9510 - precision: 0.2772 - recall: 1.0000 - auc: 0.9754 - f1score: 0.4341 - val_loss: 101.0428 - val_accuracy: 0.8014 - val_precision: 0.0357 - val_recall: 0.3333 - val_auc: 0.8937 - val_f1score: 0.0645\n",
      "Epoch 138/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 85.7923 - accuracy: 0.7555 - precision: 0.0692 - recall: 0.9643 - auc: 0.8069 - f1score: 0.1292 - val_loss: 102.0526 - val_accuracy: 0.6233 - val_precision: 0.0357 - val_recall: 0.6667 - val_auc: 0.6342 - val_f1score: 0.0678\n",
      "Epoch 139/200\n",
      "47/47 [==============================] - 58s 1s/step - loss: 85.0152 - accuracy: 0.8737 - precision: 0.1296 - recall: 1.0000 - auc: 0.9261 - f1score: 0.2295 - val_loss: 99.0546 - val_accuracy: 0.9041 - val_precision: 0.0769 - val_recall: 0.3333 - val_auc: 0.9623 - val_f1score: 0.1250\n",
      "Epoch 140/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 84.7782 - accuracy: 0.6441 - precision: 0.0469 - recall: 0.9286 - auc: 0.6730 - f1score: 0.0893 - val_loss: 124.5980 - val_accuracy: 0.0548 - val_precision: 0.0213 - val_recall: 1.0000 - val_auc: 0.0483 - val_f1score: 0.0417\n",
      "Epoch 141/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 84.2768 - accuracy: 0.5796 - precision: 0.0414 - recall: 0.9643 - auc: 0.5995 - f1score: 0.0794 - val_loss: 104.4072 - val_accuracy: 0.3493 - val_precision: 0.0306 - val_recall: 1.0000 - val_auc: 0.3328 - val_f1score: 0.0594\n",
      "Epoch 142/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 83.3083 - accuracy: 0.6837 - precision: 0.0543 - recall: 0.9643 - auc: 0.7218 - f1score: 0.1029 - val_loss: 99.2868 - val_accuracy: 0.6233 - val_precision: 0.0357 - val_recall: 0.6667 - val_auc: 0.6772 - val_f1score: 0.0678\n",
      "Epoch 143/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 82.8822 - accuracy: 0.6743 - precision: 0.0528 - recall: 0.9643 - auc: 0.7062 - f1score: 0.1002 - val_loss: 96.4798 - val_accuracy: 0.8973 - val_precision: 0.0714 - val_recall: 0.3333 - val_auc: 0.9628 - val_f1score: 0.1176\n",
      "Epoch 144/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 82.0446 - accuracy: 0.7441 - precision: 0.0663 - recall: 0.9643 - auc: 0.7902 - f1score: 0.1241 - val_loss: 96.0198 - val_accuracy: 0.8562 - val_precision: 0.0500 - val_recall: 0.3333 - val_auc: 0.9174 - val_f1score: 0.0870\n",
      "Epoch 145/200\n",
      "47/47 [==============================] - 60s 1s/step - loss: 81.2809 - accuracy: 0.8711 - precision: 0.1273 - recall: 1.0000 - auc: 0.9318 - f1score: 0.2258 - val_loss: 96.2238 - val_accuracy: 0.7192 - val_precision: 0.0476 - val_recall: 0.6667 - val_auc: 0.7836 - val_f1score: 0.0889\n",
      "Epoch 146/200\n",
      "47/47 [==============================] - 63s 1s/step - loss: 80.7031 - accuracy: 0.8214 - precision: 0.0925 - recall: 0.9643 - auc: 0.8790 - f1score: 0.1688 - val_loss: 104.3443 - val_accuracy: 0.2603 - val_precision: 0.0270 - val_recall: 1.0000 - val_auc: 0.1999 - val_f1score: 0.0526\n",
      "Epoch 147/200\n",
      "47/47 [==============================] - 65s 1s/step - loss: 79.9852 - accuracy: 0.8475 - precision: 0.1098 - recall: 1.0000 - auc: 0.8956 - f1score: 0.1979 - val_loss: 94.4589 - val_accuracy: 0.7945 - val_precision: 0.0345 - val_recall: 0.3333 - val_auc: 0.8794 - val_f1score: 0.0625\n",
      "Epoch 148/200\n",
      "47/47 [==============================] - 59s 1s/step - loss: 79.3652 - accuracy: 0.9140 - precision: 0.1795 - recall: 1.0000 - auc: 0.9557 - f1score: 0.3043 - val_loss: 93.4088 - val_accuracy: 0.8904 - val_precision: 0.0667 - val_recall: 0.3333 - val_auc: 0.9453 - val_f1score: 0.1111\n",
      "Epoch 149/200\n",
      "47/47 [==============================] - 62s 1s/step - loss: 78.7605 - accuracy: 0.8590 - precision: 0.1176 - recall: 1.0000 - auc: 0.9071 - f1score: 0.2105 - val_loss: 93.2556 - val_accuracy: 0.7466 - val_precision: 0.0278 - val_recall: 0.3333 - val_auc: 0.8821 - val_f1score: 0.0513\n",
      "Epoch 150/200\n",
      "47/47 [==============================] - 61s 1s/step - loss: 78.1155 - accuracy: 0.9335 - precision: 0.2205 - recall: 1.0000 - auc: 0.9750 - f1score: 0.3613 - val_loss: 92.7483 - val_accuracy: 0.7671 - val_precision: 0.0303 - val_recall: 0.3333 - val_auc: 0.8707 - val_f1score: 0.0556\n",
      "Epoch 151/200\n",
      "47/47 [==============================] - 63s 1s/step - loss: 77.6202 - accuracy: 0.8388 - precision: 0.1015 - recall: 0.9643 - auc: 0.8873 - f1score: 0.1837 - val_loss: 100.4372 - val_accuracy: 0.2945 - val_precision: 0.0283 - val_recall: 1.0000 - val_auc: 0.2606 - val_f1score: 0.0550\n",
      "Epoch 152/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 77.1901 - accuracy: 0.7354 - precision: 0.0643 - recall: 0.9643 - auc: 0.7762 - f1score: 0.1205 - val_loss: 90.5224 - val_accuracy: 0.9589 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9770 - val_f1score: 0.0000e+00\n",
      "Epoch 153/200\n",
      "47/47 [==============================] - 59s 1s/step - loss: 77.2714 - accuracy: 0.5487 - precision: 0.0360 - recall: 0.8929 - auc: 0.5470 - f1score: 0.0693 - val_loss: 96.1321 - val_accuracy: 0.2534 - val_precision: 0.0268 - val_recall: 1.0000 - val_auc: 0.2111 - val_f1score: 0.0522\n",
      "Epoch 154/200\n",
      "47/47 [==============================] - 58s 1s/step - loss: 76.0307 - accuracy: 0.7730 - precision: 0.0765 - recall: 1.0000 - auc: 0.8231 - f1score: 0.1421 - val_loss: 89.5809 - val_accuracy: 0.8562 - val_precision: 0.0500 - val_recall: 0.3333 - val_auc: 0.9182 - val_f1score: 0.0870\n",
      "Epoch 155/200\n",
      "47/47 [==============================] - 57s 1s/step - loss: 75.2440 - accuracy: 0.8549 - precision: 0.1148 - recall: 1.0000 - auc: 0.9159 - f1score: 0.2059 - val_loss: 90.4248 - val_accuracy: 0.7055 - val_precision: 0.0455 - val_recall: 0.6667 - val_auc: 0.7622 - val_f1score: 0.0851\n",
      "Epoch 156/200\n",
      "47/47 [==============================] - 59s 1s/step - loss: 74.6930 - accuracy: 0.9013 - precision: 0.1600 - recall: 1.0000 - auc: 0.9493 - f1score: 0.2759 - val_loss: 88.3901 - val_accuracy: 0.8425 - val_precision: 0.0455 - val_recall: 0.3333 - val_auc: 0.9070 - val_f1score: 0.0800\n",
      "Epoch 157/200\n",
      "47/47 [==============================] - 60s 1s/step - loss: 74.2331 - accuracy: 0.9537 - precision: 0.2887 - recall: 1.0000 - auc: 0.9827 - f1score: 0.4480 - val_loss: 87.6925 - val_accuracy: 0.8904 - val_precision: 0.0667 - val_recall: 0.3333 - val_auc: 0.9449 - val_f1score: 0.1111\n",
      "Epoch 158/200\n",
      "47/47 [==============================] - 64s 1s/step - loss: 73.7305 - accuracy: 0.8717 - precision: 0.1279 - recall: 1.0000 - auc: 0.9268 - f1score: 0.2267 - val_loss: 86.8779 - val_accuracy: 0.9384 - val_precision: 0.1250 - val_recall: 0.3333 - val_auc: 0.9684 - val_f1score: 0.1818\n",
      "Epoch 159/200\n",
      "47/47 [==============================] - 64s 1s/step - loss: 73.5874 - accuracy: 0.7166 - precision: 0.0583 - recall: 0.9286 - auc: 0.7474 - f1score: 0.1097 - val_loss: 90.2423 - val_accuracy: 0.4658 - val_precision: 0.0370 - val_recall: 1.0000 - val_auc: 0.4531 - val_f1score: 0.0714\n",
      "Epoch 160/200\n",
      "47/47 [==============================] - 64s 1s/step - loss: 73.1143 - accuracy: 0.5037 - precision: 0.0353 - recall: 0.9643 - auc: 0.5186 - f1score: 0.0681 - val_loss: 93.4535 - val_accuracy: 0.2877 - val_precision: 0.0280 - val_recall: 1.0000 - val_auc: 0.2239 - val_f1score: 0.0545\n",
      "Epoch 161/200\n",
      "47/47 [==============================] - 62s 1s/step - loss: 72.5241 - accuracy: 0.6864 - precision: 0.0548 - recall: 0.9643 - auc: 0.7237 - f1score: 0.1036 - val_loss: 86.5531 - val_accuracy: 0.7534 - val_precision: 0.0541 - val_recall: 0.6667 - val_auc: 0.8269 - val_f1score: 0.1000\n",
      "Epoch 162/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 72.8352 - accuracy: 0.4352 - precision: 0.0301 - recall: 0.9286 - auc: 0.4289 - f1score: 0.0582 - val_loss: 86.5946 - val_accuracy: 0.7123 - val_precision: 0.0465 - val_recall: 0.6667 - val_auc: 0.7807 - val_f1score: 0.0870\n",
      "Epoch 163/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 71.5015 - accuracy: 0.7267 - precision: 0.0624 - recall: 0.9643 - auc: 0.7787 - f1score: 0.1171 - val_loss: 85.2661 - val_accuracy: 0.8288 - val_precision: 0.0417 - val_recall: 0.3333 - val_auc: 0.8849 - val_f1score: 0.0741\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 56s 1s/step - loss: 70.9652 - accuracy: 0.6729 - precision: 0.0526 - recall: 0.9643 - auc: 0.7249 - f1score: 0.0998 - val_loss: 87.6205 - val_accuracy: 0.5548 - val_precision: 0.0441 - val_recall: 1.0000 - val_auc: 0.5581 - val_f1score: 0.0845\n",
      "Epoch 165/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 70.2546 - accuracy: 0.9033 - precision: 0.1628 - recall: 1.0000 - auc: 0.9446 - f1score: 0.2800 - val_loss: 84.5089 - val_accuracy: 0.8288 - val_precision: 0.0769 - val_recall: 0.6667 - val_auc: 0.8678 - val_f1score: 0.1379\n",
      "Epoch 166/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 69.6849 - accuracy: 0.9006 - precision: 0.1591 - recall: 1.0000 - auc: 0.9456 - f1score: 0.2745 - val_loss: 83.4005 - val_accuracy: 0.8973 - val_precision: 0.0714 - val_recall: 0.3333 - val_auc: 0.9337 - val_f1score: 0.1176\n",
      "Epoch 167/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 69.3010 - accuracy: 0.9328 - precision: 0.2188 - recall: 1.0000 - auc: 0.9733 - f1score: 0.3590 - val_loss: 82.8462 - val_accuracy: 0.8973 - val_precision: 0.0714 - val_recall: 0.3333 - val_auc: 0.9397 - val_f1score: 0.1176\n",
      "Epoch 168/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 68.9932 - accuracy: 0.8865 - precision: 0.1421 - recall: 1.0000 - auc: 0.9345 - f1score: 0.2489 - val_loss: 82.0146 - val_accuracy: 0.9247 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9636 - val_f1score: 0.0000e+00\n",
      "Epoch 169/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 68.4271 - accuracy: 0.8220 - precision: 0.0900 - recall: 0.9286 - auc: 0.8620 - f1score: 0.1640 - val_loss: 83.1843 - val_accuracy: 0.7192 - val_precision: 0.0476 - val_recall: 0.6667 - val_auc: 0.7556 - val_f1score: 0.0889\n",
      "Epoch 170/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 68.1663 - accuracy: 0.6817 - precision: 0.0540 - recall: 0.9643 - auc: 0.7187 - f1score: 0.1023 - val_loss: 82.6140 - val_accuracy: 0.7123 - val_precision: 0.0465 - val_recall: 0.6667 - val_auc: 0.7740 - val_f1score: 0.0870\n",
      "Epoch 171/200\n",
      "47/47 [==============================] - 56s 1s/step - loss: 67.5483 - accuracy: 0.8892 - precision: 0.1451 - recall: 1.0000 - auc: 0.9440 - f1score: 0.2534 - val_loss: 81.1026 - val_accuracy: 0.8151 - val_precision: 0.0385 - val_recall: 0.3333 - val_auc: 0.8903 - val_f1score: 0.0690\n",
      "Epoch 172/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 67.1292 - accuracy: 0.8496 - precision: 0.1111 - recall: 1.0000 - auc: 0.8914 - f1score: 0.2000 - val_loss: 81.3168 - val_accuracy: 0.7603 - val_precision: 0.0294 - val_recall: 0.3333 - val_auc: 0.8399 - val_f1score: 0.0541\n",
      "Epoch 173/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 66.6787 - accuracy: 0.8758 - precision: 0.1280 - recall: 0.9643 - auc: 0.9284 - f1score: 0.2259 - val_loss: 82.1317 - val_accuracy: 0.6644 - val_precision: 0.0400 - val_recall: 0.6667 - val_auc: 0.6868 - val_f1score: 0.0755\n",
      "Epoch 174/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 66.3141 - accuracy: 0.8328 - precision: 0.1011 - recall: 1.0000 - auc: 0.8910 - f1score: 0.1836 - val_loss: 79.5492 - val_accuracy: 0.8836 - val_precision: 0.0625 - val_recall: 0.3333 - val_auc: 0.9386 - val_f1score: 0.1053\n",
      "Epoch 175/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 65.8783 - accuracy: 0.7609 - precision: 0.0707 - recall: 0.9643 - auc: 0.8086 - f1score: 0.1317 - val_loss: 80.7264 - val_accuracy: 0.6781 - val_precision: 0.0417 - val_recall: 0.6667 - val_auc: 0.7125 - val_f1score: 0.0784\n",
      "Epoch 176/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 65.3782 - accuracy: 0.7495 - precision: 0.0677 - recall: 0.9643 - auc: 0.8034 - f1score: 0.1265 - val_loss: 80.5833 - val_accuracy: 0.6918 - val_precision: 0.0435 - val_recall: 0.6667 - val_auc: 0.7099 - val_f1score: 0.0816\n",
      "Epoch 177/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 64.9492 - accuracy: 0.9295 - precision: 0.2105 - recall: 1.0000 - auc: 0.9699 - f1score: 0.3478 - val_loss: 78.4385 - val_accuracy: 0.8630 - val_precision: 0.0526 - val_recall: 0.3333 - val_auc: 0.9017 - val_f1score: 0.0909\n",
      "Epoch 178/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 64.8806 - accuracy: 0.7038 - precision: 0.0578 - recall: 0.9643 - auc: 0.7428 - f1score: 0.1091 - val_loss: 78.2619 - val_accuracy: 0.7671 - val_precision: 0.0303 - val_recall: 0.3333 - val_auc: 0.8571 - val_f1score: 0.0556\n",
      "Epoch 179/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 64.0760 - accuracy: 0.9221 - precision: 0.1944 - recall: 1.0000 - auc: 0.9674 - f1score: 0.3256 - val_loss: 78.5817 - val_accuracy: 0.7123 - val_precision: 0.0465 - val_recall: 0.6667 - val_auc: 0.7699 - val_f1score: 0.0870\n",
      "Epoch 180/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 64.0368 - accuracy: 0.7173 - precision: 0.0604 - recall: 0.9643 - auc: 0.7540 - f1score: 0.1137 - val_loss: 100.7863 - val_accuracy: 0.0685 - val_precision: 0.0216 - val_recall: 1.0000 - val_auc: 0.0566 - val_f1score: 0.0423\n",
      "Epoch 181/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 63.6368 - accuracy: 0.8039 - precision: 0.0875 - recall: 1.0000 - auc: 0.8464 - f1score: 0.1609 - val_loss: 76.5013 - val_accuracy: 0.8288 - val_precision: 0.0417 - val_recall: 0.3333 - val_auc: 0.9057 - val_f1score: 0.0741\n",
      "Epoch 182/200\n",
      "47/47 [==============================] - 53s 1s/step - loss: 62.9177 - accuracy: 0.9181 - precision: 0.1867 - recall: 1.0000 - auc: 0.9638 - f1score: 0.3146 - val_loss: 75.7780 - val_accuracy: 0.9041 - val_precision: 0.0769 - val_recall: 0.3333 - val_auc: 0.9437 - val_f1score: 0.1250\n",
      "Epoch 183/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 62.5088 - accuracy: 0.9389 - precision: 0.2353 - recall: 1.0000 - auc: 0.9710 - f1score: 0.3810 - val_loss: 75.7764 - val_accuracy: 0.8630 - val_precision: 0.0526 - val_recall: 0.3333 - val_auc: 0.9148 - val_f1score: 0.0909\n",
      "Epoch 184/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 62.1177 - accuracy: 0.9456 - precision: 0.2569 - recall: 1.0000 - auc: 0.9771 - f1score: 0.4088 - val_loss: 75.0043 - val_accuracy: 0.9110 - val_precision: 0.0833 - val_recall: 0.3333 - val_auc: 0.9439 - val_f1score: 0.1333\n",
      "Epoch 185/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 61.7501 - accuracy: 0.9355 - precision: 0.2258 - recall: 1.0000 - auc: 0.9772 - f1score: 0.3684 - val_loss: 74.9655 - val_accuracy: 0.8356 - val_precision: 0.0435 - val_recall: 0.3333 - val_auc: 0.8991 - val_f1score: 0.0769\n",
      "Epoch 186/200\n",
      "47/47 [==============================] - 53s 1s/step - loss: 61.3494 - accuracy: 0.8932 - precision: 0.1497 - recall: 1.0000 - auc: 0.9452 - f1score: 0.2605 - val_loss: 74.6155 - val_accuracy: 0.8288 - val_precision: 0.0417 - val_recall: 0.3333 - val_auc: 0.8968 - val_f1score: 0.0741\n",
      "Epoch 187/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 61.0084 - accuracy: 0.9382 - precision: 0.2333 - recall: 1.0000 - auc: 0.9765 - f1score: 0.3784 - val_loss: 74.0653 - val_accuracy: 0.8767 - val_precision: 0.0588 - val_recall: 0.3333 - val_auc: 0.9156 - val_f1score: 0.1000\n",
      "Epoch 188/200\n",
      "47/47 [==============================] - 53s 1s/step - loss: 60.5156 - accuracy: 0.9496 - precision: 0.2718 - recall: 1.0000 - auc: 0.9800 - f1score: 0.4275 - val_loss: 73.4352 - val_accuracy: 0.9041 - val_precision: 0.0769 - val_recall: 0.3333 - val_auc: 0.9523 - val_f1score: 0.1250\n",
      "Epoch 189/200\n",
      "47/47 [==============================] - 53s 1s/step - loss: 60.2650 - accuracy: 0.9570 - precision: 0.3043 - recall: 1.0000 - auc: 0.9820 - f1score: 0.4667 - val_loss: 72.9810 - val_accuracy: 0.8836 - val_precision: 0.0625 - val_recall: 0.3333 - val_auc: 0.9445 - val_f1score: 0.1053\n",
      "Epoch 190/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 60.0836 - accuracy: 0.7623 - precision: 0.0711 - recall: 0.9643 - auc: 0.7973 - f1score: 0.1324 - val_loss: 72.2921 - val_accuracy: 0.9315 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9769 - val_f1score: 0.0000e+00\n",
      "Epoch 191/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 59.5582 - accuracy: 0.8744 - precision: 0.1302 - recall: 1.0000 - auc: 0.9256 - f1score: 0.2305 - val_loss: 72.0450 - val_accuracy: 0.9110 - val_precision: 0.0833 - val_recall: 0.3333 - val_auc: 0.9452 - val_f1score: 0.1333\n",
      "Epoch 192/200\n",
      "47/47 [==============================] - 53s 1s/step - loss: 59.1773 - accuracy: 0.8959 - precision: 0.1530 - recall: 1.0000 - auc: 0.9506 - f1score: 0.2654 - val_loss: 73.0172 - val_accuracy: 0.7192 - val_precision: 0.0476 - val_recall: 0.6667 - val_auc: 0.7839 - val_f1score: 0.0889\n",
      "Epoch 193/200\n",
      "47/47 [==============================] - 53s 1s/step - loss: 59.4441 - accuracy: 0.5628 - precision: 0.0399 - recall: 0.9643 - auc: 0.5647 - f1score: 0.0766 - val_loss: 71.8113 - val_accuracy: 0.8562 - val_precision: 0.0500 - val_recall: 0.3333 - val_auc: 0.9109 - val_f1score: 0.0870\n",
      "Epoch 194/200\n",
      "47/47 [==============================] - 55s 1s/step - loss: 58.7706 - accuracy: 0.7938 - precision: 0.0811 - recall: 0.9643 - auc: 0.8520 - f1score: 0.1496 - val_loss: 71.1257 - val_accuracy: 0.9315 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9565 - val_f1score: 0.0000e+00\n",
      "Epoch 195/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 58.1537 - accuracy: 0.9396 - precision: 0.2373 - recall: 1.0000 - auc: 0.9769 - f1score: 0.3836 - val_loss: 71.1114 - val_accuracy: 0.8493 - val_precision: 0.0476 - val_recall: 0.3333 - val_auc: 0.9032 - val_f1score: 0.0833\n",
      "Epoch 196/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 57.7870 - accuracy: 0.8583 - precision: 0.1172 - recall: 1.0000 - auc: 0.9116 - f1score: 0.2097 - val_loss: 71.4464 - val_accuracy: 0.7671 - val_precision: 0.0303 - val_recall: 0.3333 - val_auc: 0.8240 - val_f1score: 0.0556\n",
      "Epoch 197/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 57.7171 - accuracy: 0.7616 - precision: 0.0709 - recall: 0.9643 - auc: 0.7975 - f1score: 0.1320 - val_loss: 69.7746 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9790 - val_f1score: 0.0000e+00\n",
      "Epoch 198/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 57.3080 - accuracy: 0.8308 - precision: 0.1000 - recall: 1.0000 - auc: 0.8827 - f1score: 0.1818 - val_loss: 70.4112 - val_accuracy: 0.7671 - val_precision: 0.0303 - val_recall: 0.3333 - val_auc: 0.8093 - val_f1score: 0.0556\n",
      "Epoch 199/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 56.9605 - accuracy: 0.7394 - precision: 0.0652 - recall: 0.9643 - auc: 0.7884 - f1score: 0.1222 - val_loss: 69.4057 - val_accuracy: 0.8973 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9483 - val_f1score: 0.0000e+00\n",
      "Epoch 200/200\n",
      "47/47 [==============================] - 54s 1s/step - loss: 56.7415 - accuracy: 0.8469 - precision: 0.1063 - recall: 0.9643 - auc: 0.8994 - f1score: 0.1915 - val_loss: 72.0361 - val_accuracy: 0.5616 - val_precision: 0.0308 - val_recall: 0.6667 - val_auc: 0.5679 - val_f1score: 0.0588\n",
      "WARNING:tensorflow:From <ipython-input-1-9cd04830253e>:146: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "6/6 [==============================] - 4s 696ms/step - loss: 75.7573 - accuracy: 0.5165 - precision: 0.0435 - recall: 1.0000 - auc: 0.5074 - f1score: 0.0833\n",
      "loss  =  75.75731658935547\n",
      "accuracy  =  0.5164835453033447\n",
      "precision  =  0.043478261679410934\n",
      "recall  =  1.0\n",
      "auc  =  0.5073662400245667\n",
      "f1score  =  0.0833333358168602\n",
      "WARNING:tensorflow:From <ipython-input-1-9cd04830253e>:290: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "True (-)ves:  90 \n",
      "False (+)ves:  88 \n",
      "False (-)ves:  0 \n",
      "True (+)ves:  4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "import dill\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.summary as tf_summary\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from math import ceil\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, CategoricalAccuracy, Precision, Recall, AUC\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from models.models import *\n",
    "from visualization.visualize import *\n",
    "from custom.metrics import F1Score\n",
    "from preprocess import remove_text\n",
    "from pathlib import Path\n",
    "\n",
    "def get_class_weights(histogram, class_multiplier=None):\n",
    "    '''\n",
    "    Computes weights for each class to be applied in the loss function during training.\n",
    "    :param histogram: A list depicting the number of each item in different class\n",
    "    :param class_multiplier: List of values to multiply the calculated class weights by. For further control of class weighting.\n",
    "    :return: A dictionary containing weights for each class\n",
    "    '''\n",
    "    weights = [None] * len(histogram)\n",
    "    for i in range(len(histogram)):\n",
    "        weights[i] = (1.0 / len(histogram)) * sum(histogram) / histogram[i]\n",
    "    class_weight = {i: weights[i] for i in range(len(histogram))}\n",
    "    if class_multiplier is not None:\n",
    "        class_weight = {i: class_weight[i] * class_multiplier[i] for i in range(len(histogram))} # changed from list to dict by addin '{i: }'\n",
    "    print(\"Class weights: \", class_weight)\n",
    "    return class_weight\n",
    "\n",
    "\n",
    "def random_minority_oversample(train_set):\n",
    "    '''\n",
    "    Oversample the minority class using the specified algorithm\n",
    "    :param train_set: Training set image file names and labels\n",
    "    :return: A new training set containing oversampled examples\n",
    "    '''\n",
    "    X_train = train_set[[x for x in train_set.columns if x != 'label']].to_numpy()\n",
    "    if X_train.shape[1] == 1:\n",
    "        X_train = np.expand_dims(X_train, axis=-1)\n",
    "    Y_train = train_set['label'].to_numpy()\n",
    "    sampler = RandomOverSampler(random_state=np.random.randint(0, high=1000))\n",
    "    X_resampled, Y_resampled = sampler.fit_resample(X_train, Y_train)\n",
    "    filenames = X_resampled[:, 1]     # Filename is in second column\n",
    "    label_strs = X_resampled[:, 2]    # Class name is in second column\n",
    "    print(\"Train set shape before oversampling: \", X_train.shape, \" Train set shape after resampling: \", X_resampled.shape)\n",
    "    train_set_resampled = pd.DataFrame({'filename': filenames, 'label': Y_resampled, 'label_str': label_strs})\n",
    "    return train_set_resampled\n",
    "\n",
    "\n",
    "def train_model(cfg, data, callbacks, verbose=1):\n",
    "    '''\n",
    "    Train a and evaluate model on given data.\n",
    "    :param cfg: Project config (from config.yml)\n",
    "    :param data: dict of partitioned dataset\n",
    "    :param callbacks: list of callbacks for Keras model\n",
    "    :param verbose: Verbosity mode to pass to model.fit_generator()\n",
    "    :return: Trained model and associated performance metrics on the test set\n",
    "    '''\n",
    "\n",
    "    # If set in config file, oversample the minority class\n",
    "    if cfg['TRAIN']['IMB_STRATEGY'] == 'random_oversample':\n",
    "        data['TRAIN'] = random_minority_oversample(data['TRAIN'])\n",
    "\n",
    "    # Create ImageDataGenerators\n",
    "    train_img_gen = ImageDataGenerator(rotation_range=10, preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "    val_img_gen = ImageDataGenerator(preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "    test_img_gen = ImageDataGenerator(preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "\n",
    "    # Create DataFrameIterators\n",
    "    raw_data = Path('C:/Users/PaulDS3/Downloads/project/covid_cxr/data/') # replace cfg['PATHS']['RAW_DATA']\n",
    "    out_class_ind = Path('C:/Users/PaulDS3/Downloads/project/covid_cxr/interpretability/output_class_indices.pkl') # replace cfg['PATHS']['OUTPUT_CLASS_INDICES']\n",
    "    img_shape = tuple(cfg['DATA']['IMG_DIM'])\n",
    "    y_col = 'label_str'\n",
    "    class_mode = 'categorical'\n",
    "    train_generator = train_img_gen.flow_from_dataframe(dataframe=data['TRAIN'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col=y_col, target_size=img_shape, batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "        class_mode=class_mode, validate_filenames=False)\n",
    "    val_generator = val_img_gen.flow_from_dataframe(dataframe=data['VAL'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col=y_col, target_size=img_shape, batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "        class_mode=class_mode, validate_filenames=False)\n",
    "    test_generator = test_img_gen.flow_from_dataframe(dataframe=data['TEST'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col=y_col, target_size=img_shape, batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "        class_mode=class_mode, validate_filenames=False, shuffle=False)\n",
    "\n",
    "    # Save model's ordering of class indices\n",
    "    dill.dump(test_generator.class_indices, open(out_class_ind, 'wb')) # replaced cfg['PATHS']['OUTPUT_CLASS_INDICES']\n",
    "    # Apply class imbalance strategy. We have many more X-rays negative for COVID-19 than positive.\n",
    "    histogram = np.bincount(np.array(train_generator.labels).astype(int))  # Get class distribution\n",
    "    class_weight = None\n",
    "    if cfg['TRAIN']['IMB_STRATEGY'] == 'class_weight':\n",
    "        class_multiplier = cfg['TRAIN']['CLASS_MULTIPLIER']\n",
    "        class_multiplier = [class_multiplier[cfg['DATA']['CLASSES'].index(c)] for c in test_generator.class_indices]\n",
    "        class_weight = get_class_weights(histogram, class_multiplier)\n",
    "\n",
    "    # Define metrics.\n",
    "    covid_class_idx = test_generator.class_indices['COVID-19']   # Get index of COVID-19 class\n",
    "    thresholds = 1.0 / len(cfg['DATA']['CLASSES'])      # Binary classification threshold for a class\n",
    "    metrics = [CategoricalAccuracy(name='accuracy'),\n",
    "               Precision(name='precision', thresholds=thresholds, class_id=covid_class_idx),\n",
    "               Recall(name='recall', thresholds=thresholds, class_id=covid_class_idx),\n",
    "               AUC(name='auc'),\n",
    "               F1Score(name='f1score', thresholds=thresholds, class_id=covid_class_idx)]\n",
    "\n",
    "    # Define the model.\n",
    "    print('Training distribution: ', ['Class ' + list(test_generator.class_indices.keys())[i] + ': ' + str(histogram[i]) + '. '\n",
    "           for i in range(len(histogram))])\n",
    "    input_shape = cfg['DATA']['IMG_DIM'] + [3]\n",
    "    num_gpus = cfg['TRAIN']['NUM_GPUS']\n",
    "    if cfg['TRAIN']['MODEL_DEF'] == 'dcnn_resnet':\n",
    "        model_def = dcnn_resnet\n",
    "    elif cfg['TRAIN']['MODEL_DEF'] == 'resnet50v2':\n",
    "        model_def = resnet50v2\n",
    "    else:\n",
    "        model_def = resnet101v2\n",
    "    if cfg['TRAIN']['CLASS_MODE'] == 'binary':\n",
    "        histogram = np.bincount(data['TRAIN']['label'].astype(int))\n",
    "        output_bias = np.log([histogram[i] / (np.sum(histogram) - histogram[i]) for i in range(histogram.shape[0])])\n",
    "        model = model_def(cfg['NN']['DCNN_BINARY'], input_shape, metrics, 2, output_bias=output_bias, gpus=num_gpus) #removed gpus=num_gpus\n",
    "    else:\n",
    "        n_classes = len(cfg['DATA']['CLASSES'])\n",
    "        histogram = np.bincount(data['TRAIN']['label'].astype(int))\n",
    "        output_bias = np.log([histogram[i] / (np.sum(histogram) - histogram[i]) for i in range(histogram.shape[0])])\n",
    "        model = model_def(cfg['NN']['DCNN_MULTICLASS'], input_shape, metrics, n_classes, output_bias=output_bias, gpus=num_gpus) #removed gpus=num_gpus\n",
    "\n",
    "    # Train the model.\n",
    "    steps_per_epoch = ceil(train_generator.n / train_generator.batch_size)\n",
    "    val_steps = ceil(val_generator.n / val_generator.batch_size)\n",
    "    # changed model.fit_generator to model.fit()\n",
    "    history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=cfg['TRAIN']['EPOCHS'],\n",
    "                                  validation_data=val_generator, validation_steps=val_steps, callbacks=callbacks,\n",
    "                                  verbose=verbose, class_weight=class_weight)\n",
    "\n",
    "    # Run the model on the test set and print the resulting performance metrics.\n",
    "    test_results = model.evaluate_generator(test_generator, verbose=1)\n",
    "    test_metrics = {}\n",
    "    test_summary_str = [['**Metric**', '**Value**']]\n",
    "    for metric, value in zip(model.metrics_names, test_results):\n",
    "        test_metrics[metric] = value\n",
    "        print(metric, ' = ', value)\n",
    "        test_summary_str.append([metric, str(value)])\n",
    "    return model, test_metrics, test_generator\n",
    "\n",
    "\n",
    "def multi_train(cfg, data, callbacks, base_log_dir):\n",
    "    '''\n",
    "    Trains a model a series of times and returns the model with the best test set metric (specified in cfg)\n",
    "    :param cfg: Project config (from config.yml)\n",
    "    :param data: Partitioned dataset\n",
    "    :param callbacks: List of callbacks to pass to model.fit()\n",
    "    :param base_log_dir: Base directory to write logs\n",
    "    :return: The trained Keras model with best test set performance on the metric specified in cfg\n",
    "    '''\n",
    "\n",
    "    # Load order of metric preference\n",
    "    metric_preference = cfg['TRAIN']['METRIC_PREFERENCE']\n",
    "    best_metrics = dict.fromkeys(metric_preference, 0.0)\n",
    "    if 'loss' in metric_preference:\n",
    "        best_metrics['loss'] = 100000.0\n",
    "\n",
    "    # Train NUM_RUNS models and return the best one according to the preferred metrics\n",
    "    for i in range(cfg['TRAIN']['NUM_RUNS']):\n",
    "        print(\"Training run \", i+1, \" / \", cfg['TRAIN']['NUM_RUNS'])\n",
    "        cur_callbacks = callbacks.copy()\n",
    "        cur_date = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "        if base_log_dir is not None:\n",
    "            log_dir = base_log_dir + cur_date\n",
    "            cur_callbacks.append(TensorBoard(log_dir=log_dir, histogram_freq=1))\n",
    "\n",
    "        # Train the model and evaluate performance on test set\n",
    "        new_model, test_metrics, test_generator = train_model(cfg, data, cur_callbacks, verbose=1)\n",
    "\n",
    "        # Log test set results and images\n",
    "        if base_log_dir is not None:\n",
    "            log_test_results(cfg, new_model, test_generator, test_metrics, log_dir)\n",
    "\n",
    "        # If this model outperforms the previous ones based on the specified metric preferences, save this one.\n",
    "        for i in range(len(metric_preference)):\n",
    "            if (((metric_preference[i] == 'loss') and (test_metrics[metric_preference[i]] < best_metrics[metric_preference[i]]))\n",
    "                    or ((metric_preference[i] != 'loss') and (test_metrics[metric_preference[i]] > best_metrics[metric_preference[i]]))):\n",
    "                best_model = new_model\n",
    "                best_metrics = test_metrics\n",
    "                best_generator = test_generator\n",
    "                best_model_date = cur_date\n",
    "                break\n",
    "            elif (test_metrics[metric_preference[i]] == best_metrics[metric_preference[i]]):\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    print(\"Best model test metrics: \", best_metrics)\n",
    "    return best_model, best_metrics, best_generator, best_model_date\n",
    "\n",
    "\n",
    "def random_hparam_search(cfg, data, callbacks, log_dir):\n",
    "    '''\n",
    "    Conduct a random hyperparameter search over the ranges given for the hyperparameters in config.yml and log results\n",
    "    in TensorBoard. Model is trained x times for y random combinations of hyperparameters.\n",
    "    :param cfg: Project config\n",
    "    :param data: Dict containing the partitioned datasets\n",
    "    :param callbacks: List of callbacks for Keras model (excluding TensorBoard)\n",
    "    :param log_dir: Base directory in which to store logs\n",
    "    :return: (Last model trained, resultant test set metrics, test data generator)\n",
    "    '''\n",
    "\n",
    "    # Define HParam objects for each hyperparameter we wish to tune.\n",
    "    hp_ranges = cfg['HP_SEARCH']['RANGES']\n",
    "    HPARAMS = []\n",
    "    HPARAMS.append(hp.HParam('KERNEL_SIZE', hp.Discrete(hp_ranges['KERNEL_SIZE'])))\n",
    "    HPARAMS.append(hp.HParam('MAXPOOL_SIZE', hp.Discrete(hp_ranges['MAXPOOL_SIZE'])))\n",
    "    HPARAMS.append(hp.HParam('INIT_FILTERS', hp.Discrete(hp_ranges['INIT_FILTERS'])))\n",
    "    HPARAMS.append(hp.HParam('FILTER_EXP_BASE', hp.IntInterval(hp_ranges['FILTER_EXP_BASE'][0], hp_ranges['FILTER_EXP_BASE'][1])))\n",
    "    HPARAMS.append(hp.HParam('NODES_DENSE0', hp.Discrete(hp_ranges['NODES_DENSE0'])))\n",
    "    HPARAMS.append(hp.HParam('CONV_BLOCKS', hp.IntInterval(hp_ranges['CONV_BLOCKS'][0], hp_ranges['CONV_BLOCKS'][1])))\n",
    "    HPARAMS.append(hp.HParam('DROPOUT', hp.Discrete(hp_ranges['DROPOUT'])))\n",
    "    HPARAMS.append(hp.HParam('LR', hp.RealInterval(hp_ranges['LR'][0], hp_ranges['LR'][1])))\n",
    "    HPARAMS.append(hp.HParam('OPTIMIZER', hp.Discrete(hp_ranges['OPTIMIZER'])))\n",
    "    HPARAMS.append(hp.HParam('L2_LAMBDA', hp.Discrete(hp_ranges['L2_LAMBDA'])))\n",
    "    HPARAMS.append(hp.HParam('BATCH_SIZE', hp.Discrete(hp_ranges['BATCH_SIZE'])))\n",
    "    HPARAMS.append(hp.HParam('IMB_STRATEGY', hp.Discrete(hp_ranges['IMB_STRATEGY'])))\n",
    "\n",
    "    # Define test set metrics that we wish to log to TensorBoard for each training run\n",
    "    HP_METRICS = [hp.Metric(metric, display_name='Test ' + metric) for metric in cfg['HP_SEARCH']['METRICS']]\n",
    "\n",
    "    # Configure TensorBoard to log the results\n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams_config(hparams=HPARAMS, metrics=HP_METRICS)\n",
    "\n",
    "    # Complete a number of training runs at different hparam values and log the results.\n",
    "    repeats_per_combo = cfg['HP_SEARCH']['REPEATS']   # Number of times to train the model per combination of hparams\n",
    "    num_combos = cfg['HP_SEARCH']['COMBINATIONS']     # Number of random combinations of hparams to attempt\n",
    "    num_sessions = num_combos * repeats_per_combo       # Total number of runs in this experiment\n",
    "    model_type = 'DCNN_BINARY' if cfg['TRAIN']['CLASS_MODE'] == 'binary' else 'DCNN_MULTICLASS'\n",
    "    trial_id = 0\n",
    "    for group_idx in range(num_combos):\n",
    "        rand = random.Random()\n",
    "        HPARAMS = {h: h.domain.sample_uniform(rand) for h in HPARAMS}\n",
    "        hparams = {h.name: HPARAMS[h] for h in HPARAMS}  # To pass to model definition\n",
    "        for repeat_idx in range(repeats_per_combo):\n",
    "            trial_id += 1\n",
    "            print(\"Running training session %d/%d\" % (trial_id, num_sessions))\n",
    "            print(\"Hparam values: \", {h.name: HPARAMS[h] for h in HPARAMS})\n",
    "            trial_logdir = os.path.join(log_dir, str(trial_id))     # Need specific logdir for each trial\n",
    "            callbacks_hp = callbacks + [TensorBoard(log_dir=trial_logdir, profile_batch=0, write_graph=False)]\n",
    "\n",
    "            # Set values of hyperparameters for this run in config file.\n",
    "            for h in hparams:\n",
    "                if h in ['LR', 'L2_LAMBDA']:\n",
    "                    val = 10 ** hparams[h]      # These hyperparameters are sampled on the log scale.\n",
    "                else:\n",
    "                    val = hparams[h]\n",
    "                cfg['NN'][model_type][h] = val\n",
    "\n",
    "            # Set some hyperparameters that are not specified in model definition.\n",
    "            cfg['TRAIN']['BATCH_SIZE'] = hparams['BATCH_SIZE']\n",
    "            cfg['TRAIN']['IMB_STRATEGY'] = hparams['IMB_STRATEGY']\n",
    "\n",
    "            # Run a training session and log the performance metrics on the test set to HParams dashboard in TensorBoard\n",
    "            with tf.summary.create_file_writer(trial_logdir).as_default():\n",
    "                hp.hparams(HPARAMS, trial_id=str(trial_id))\n",
    "                model, test_metrics, test_generator = train_model(cfg, data, callbacks_hp, verbose=0)\n",
    "                for metric in HP_METRICS:\n",
    "                    if metric._tag in test_metrics:\n",
    "                        tf.summary.scalar(metric._tag, test_metrics[metric._tag], step=1)   # Log test metric\n",
    "    return\n",
    "\n",
    "\n",
    "def log_test_results(cfg, model, test_generator, test_metrics, log_dir):\n",
    "    '''\n",
    "    Visualize performance of a trained model on the test set. Optionally save the model.\n",
    "    :param cfg: Project config\n",
    "    :param model: A trained Keras model\n",
    "    :param test_generator: A Keras generator for the test set\n",
    "    :param test_metrics: Dict of test set performance metrics\n",
    "    :param log_dir: Path to write TensorBoard logs\n",
    "    '''\n",
    "\n",
    "    # Visualization of test results\n",
    "    test_predictions = model.predict_generator(test_generator, verbose=0)\n",
    "    test_labels = test_generator.labels\n",
    "    covid_idx = test_generator.class_indices['COVID-19']\n",
    "    plt = plot_roc(\"Test set\", test_labels, test_predictions, class_id=covid_idx)\n",
    "    roc_img = plot_to_tensor()\n",
    "    plt = plot_confusion_matrix(test_labels, test_predictions, class_id=covid_idx)\n",
    "    cm_img = plot_to_tensor()\n",
    "\n",
    "    # Log test set results and plots in TensorBoard\n",
    "    writer = tf_summary.create_file_writer(logdir=log_dir)\n",
    "\n",
    "    # Create table of test set metrics\n",
    "    test_summary_str = [['**Metric**','**Value**']]\n",
    "    thresholds = cfg['TRAIN']['THRESHOLDS']  # Load classification thresholds\n",
    "    for metric in test_metrics:\n",
    "        if metric in ['precision', 'recall'] and isinstance(metric, list):\n",
    "            metric_values = dict(zip(thresholds, test_metrics[metric]))\n",
    "        else:\n",
    "            metric_values = test_metrics[metric]\n",
    "        test_summary_str.append([metric, str(metric_values)])\n",
    "\n",
    "    # Create table of model and train config values\n",
    "    hparam_summary_str = [['**Variable**', '**Value**']]\n",
    "    for key in cfg['TRAIN']:\n",
    "        hparam_summary_str.append([key, str(cfg['TRAIN'][key])])\n",
    "    if cfg['TRAIN']['CLASS_MODE'] == 'binary':\n",
    "        for key in cfg['NN']['DCNN_BINARY']:\n",
    "            hparam_summary_str.append([key, str(cfg['NN']['DCNN_BINARY'][key])])\n",
    "    else:\n",
    "        for key in cfg['NN']['DCNN_BINARY']:\n",
    "            hparam_summary_str.append([key, str(cfg['NN']['DCNN_BINARY'][key])])\n",
    "\n",
    "    # Write to TensorBoard logs\n",
    "    with writer.as_default():\n",
    "        tf_summary.text(name='Test set metrics', data=tf.convert_to_tensor(test_summary_str), step=0)\n",
    "        tf_summary.text(name='Run hyperparameters', data=tf.convert_to_tensor(hparam_summary_str), step=0)\n",
    "        tf_summary.image(name='ROC Curve (Test Set)', data=roc_img, step=0)\n",
    "        tf_summary.image(name='Confusion Matrix (Test Set)', data=cm_img, step=0)\n",
    "    return\n",
    "\n",
    "def train_experiment(cfg=None, experiment='single_train', save_weights=True, write_logs=True):\n",
    "    '''\n",
    "    Defines and trains HIFIS-v2 model. Prints and logs relevant metrics.\n",
    "    :param experiment: The type of training experiment. Choices are {'single_train'}\n",
    "    :param save_weights: A flag indicating whether to save the model weights\n",
    "    :param write_logs: A flag indicating whether to write TensorBoard logs\n",
    "    :return: A dictionary of metrics on the test set\n",
    "    '''\n",
    "\n",
    "    # Load project config data\n",
    "    if cfg is None:\n",
    "        cfg = yaml.full_load(open(\"C:\\\\Users\\\\PaulDS3\\\\Downloads\\\\project\\\\covid-cxr\\\\config.yml\", 'r'))\n",
    "\n",
    "    # Set logs directory\n",
    "    cur_date = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    log_dir = cfg['PATHS']['LOGS'] + \"training\\\\\" + cur_date if write_logs else None\n",
    "    if not os.path.exists(cfg['PATHS']['LOGS'] + \"training\\\\\"):\n",
    "        os.makedirs(cfg['PATHS']['LOGS'] + \"training\\\\\")\n",
    "\n",
    "    # Load dataset file paths and labels\n",
    "    data = {}\n",
    "    data['TRAIN'] = pd.read_csv(cfg['PATHS']['TRAIN_SET'])\n",
    "    data['VAL'] = pd.read_csv(cfg['PATHS']['VAL_SET'])\n",
    "    data['TEST'] = pd.read_csv(cfg['PATHS']['TEST_SET'])\n",
    "\n",
    "    # Set callbacks.\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=cfg['TRAIN']['PATIENCE'], mode='min', restore_best_weights=True)\n",
    "    callbacks = [early_stopping]\n",
    "\n",
    "    # Conduct the desired train experiment\n",
    "    if experiment == 'hparam_search':\n",
    "        log_dir = cfg['PATHS']['LOGS'] + \"hparam_search\\\\\" + cur_date\n",
    "        random_hparam_search(cfg, data, callbacks, log_dir)\n",
    "    else:\n",
    "        if experiment == 'multi_train':\n",
    "            base_log_dir = cfg['PATHS']['LOGS'] + \"training\\\\\" if write_logs else None\n",
    "            model, test_metrics, test_generator, cur_date = multi_train(cfg, data, callbacks, base_log_dir)\n",
    "        else:\n",
    "            if write_logs:\n",
    "                tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                callbacks.append(tensorboard)\n",
    "            model, test_metrics, test_generator = train_model(cfg, data, callbacks)\n",
    "            if write_logs:\n",
    "                log_test_results(cfg, model, test_generator, test_metrics, log_dir)\n",
    "        if save_weights:\n",
    "            model_path = cfg['PATHS']['MODEL_WEIGHTS'] + 'model' + cur_date + '.h5'\n",
    "            save_model(model, model_path)  # Save the model's weights\n",
    "    return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cfg = yaml.full_load(open(\"C:\\\\Users\\\\PaulDS3\\\\Downloads\\\\project\\\\covid_cxr\\\\config.yml\", 'r'))\n",
    "    train_experiment(cfg=cfg, experiment=cfg['TRAIN']['EXPERIMENT_TYPE'], save_weights=True, write_logs=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
