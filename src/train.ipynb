{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape before oversampling:  (1489, 3)  Train set shape after resampling:  (2922, 3)\n",
      "Found 2922 non-validated image filenames belonging to 2 classes.\n",
      "Found 146 non-validated image filenames belonging to 2 classes.\n",
      "Found 182 non-validated image filenames belonging to 2 classes.\n",
      "Training distribution:  ['Class COVID-19: 1461. ', 'Class non-COVID-19: 1461. ']\n",
      "MODEL CONFIG:  {'KERNEL_SIZE': '(3,3)', 'STRIDES': '(1,1)', 'INIT_FILTERS': 16, 'FILTER_EXP_BASE': 3, 'MAXPOOL_SIZE': '(2,2)', 'CONV_BLOCKS': 3, 'NODES_DENSE0': 64, 'LR': 1e-05, 'OPTIMIZER': 'adam', 'DROPOUT': 0.2, 'L2_LAMBDA': 0.0001}\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv0_0 (Conv2D)                (None, 224, 224, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 224, 224, 16) 64          conv0_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 224, 224, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv0_1 (Conv2D)                (None, 224, 224, 16) 2320        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concat0 (Concatenate)           (None, 224, 224, 19) 0           conv0_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 224, 224, 19) 76          concat0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 224, 224, 19) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 112, 112, 19) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1_0 (Conv2D)                (None, 112, 112, 48) 8256        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 112, 112, 48) 192         conv1_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 112, 112, 48) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1 (Conv2D)                (None, 112, 112, 48) 20784       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concat1 (Concatenate)           (None, 112, 112, 67) 0           conv1_1[0][0]                    \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 112, 112, 67) 268         concat1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 112, 112, 67) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 67)   0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_0 (Conv2D)                (None, 56, 56, 144)  86976       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 144)  576         conv2_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 56, 56, 144)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1 (Conv2D)                (None, 56, 56, 144)  186768      leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concat2 (Concatenate)           (None, 56, 56, 211)  0           conv2_1[0][0]                    \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 211)  844         concat2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 56, 56, 211)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 211)  0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 165424)       0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 165424)       0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           10587200    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 64)           0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            130         leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Activation)             (None, 2)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 10,894,902\n",
      "Trainable params: 10,893,892\n",
      "Non-trainable params: 1,010\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      " 1/92 [..............................] - ETA: 0s - loss: 647.6792 - accuracy: 0.5938 - precision: 0.5652 - recall: 0.8125 - auc: 0.6230 - f1score: 0.6667WARNING:tensorflow:From C:\\Users\\PaulDS3\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "92/92 [==============================] - 105s 1s/step - loss: 615.6922 - accuracy: 0.8029 - precision: 0.8008 - recall: 0.8063 - auc: 0.8703 - f1score: 0.8035 - val_loss: 484.8327 - val_accuracy: 0.9795 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9960 - val_f1score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "92/92 [==============================] - 104s 1s/step - loss: 561.8503 - accuracy: 0.9487 - precision: 0.9332 - recall: 0.9665 - auc: 0.9875 - f1score: 0.9496 - val_loss: 440.2430 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9958 - val_f1score: 0.0000e+00\n",
      "Epoch 3/100\n",
      "92/92 [==============================] - 105s 1s/step - loss: 522.0690 - accuracy: 0.9825 - precision: 0.9738 - recall: 0.9918 - auc: 0.9969 - f1score: 0.9827 - val_loss: 445.9403 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9944 - val_f1score: 0.0000e+00\n",
      "Epoch 4/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 490.8352 - accuracy: 0.9867 - precision: 0.9791 - recall: 0.9945 - auc: 0.9981 - f1score: 0.9868 - val_loss: 455.0028 - val_accuracy: 0.9795 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9835 - val_f1score: 0.0000e+00\n",
      "Epoch 5/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 464.9919 - accuracy: 0.9884 - precision: 0.9837 - recall: 0.9932 - auc: 0.9985 - f1score: 0.9884 - val_loss: 452.1978 - val_accuracy: 0.9795 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9883 - val_f1score: 0.0000e+00\n",
      "Epoch 6/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 443.2319 - accuracy: 0.9921 - precision: 0.9878 - recall: 0.9966 - auc: 0.9996 - f1score: 0.9922 - val_loss: 440.1307 - val_accuracy: 0.9452 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9849 - val_f1score: 0.0000e+00\n",
      "Epoch 7/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 424.3071 - accuracy: 0.9880 - precision: 0.9850 - recall: 0.9911 - auc: 0.9988 - f1score: 0.9881 - val_loss: 424.9737 - val_accuracy: 0.9795 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9892 - val_f1score: 0.0000e+00\n",
      "Epoch 8/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 407.5490 - accuracy: 0.9956 - precision: 0.9918 - recall: 0.9993 - auc: 0.9998 - f1score: 0.9956 - val_loss: 409.0889 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9807 - val_f1score: 0.0000e+00\n",
      "Epoch 9/100\n",
      "92/92 [==============================] - 107s 1s/step - loss: 392.3587 - accuracy: 0.9986 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - f1score: 0.9986 - val_loss: 394.4828 - val_accuracy: 0.9521 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9814 - val_f1score: 0.0000e+00\n",
      "Epoch 10/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 378.7010 - accuracy: 0.9846 - precision: 0.9790 - recall: 0.9904 - auc: 0.9979 - f1score: 0.9847 - val_loss: 380.8993 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9776 - val_f1score: 0.0000e+00\n",
      "Epoch 11/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 366.0451 - accuracy: 0.9956 - precision: 0.9945 - recall: 0.9966 - auc: 0.9998 - f1score: 0.9956 - val_loss: 368.6280 - val_accuracy: 0.9384 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9767 - val_f1score: 0.0000e+00\n",
      "Epoch 12/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 354.4679 - accuracy: 0.9945 - precision: 0.9932 - recall: 0.9959 - auc: 0.9998 - f1score: 0.9945 - val_loss: 356.8059 - val_accuracy: 0.9247 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9655 - val_f1score: 0.0000e+00\n",
      "Epoch 13/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 343.6263 - accuracy: 0.9945 - precision: 0.9918 - recall: 0.9973 - auc: 0.9998 - f1score: 0.9945 - val_loss: 346.1636 - val_accuracy: 0.9589 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9670 - val_f1score: 0.0000e+00\n",
      "Epoch 14/100\n",
      "92/92 [==============================] - 109s 1s/step - loss: 333.5833 - accuracy: 0.9997 - precision: 0.9993 - recall: 1.0000 - auc: 1.0000 - f1score: 0.9997 - val_loss: 335.9470 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9698 - val_f1score: 0.0000e+00\n",
      "Epoch 15/100\n",
      "92/92 [==============================] - 113s 1s/step - loss: 324.1602 - accuracy: 0.9973 - precision: 0.9952 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9973 - val_loss: 326.9795 - val_accuracy: 0.9384 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9681 - val_f1score: 0.0000e+00\n",
      "Epoch 16/100\n",
      "92/92 [==============================] - 116s 1s/step - loss: 315.2915 - accuracy: 0.9938 - precision: 0.9925 - recall: 0.9952 - auc: 0.9998 - f1score: 0.9938 - val_loss: 318.6214 - val_accuracy: 0.9178 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9617 - val_f1score: 0.0000e+00\n",
      "Epoch 17/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 307.0028 - accuracy: 0.9935 - precision: 0.9918 - recall: 0.9952 - auc: 0.9997 - f1score: 0.9935 - val_loss: 310.3918 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9785 - val_f1score: 0.0000e+00\n",
      "Epoch 18/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 299.0806 - accuracy: 0.9962 - precision: 0.9952 - recall: 0.9973 - auc: 0.9996 - f1score: 0.9962 - val_loss: 302.8042 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9702 - val_f1score: 0.0000e+00\n",
      "Epoch 19/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 291.7549 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - f1score: 1.0000 - val_loss: 295.3393 - val_accuracy: 0.9521 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9692 - val_f1score: 0.0000e+00\n",
      "Epoch 20/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 284.7415 - accuracy: 0.9962 - precision: 0.9959 - recall: 0.9966 - auc: 0.9999 - f1score: 0.9962 - val_loss: 288.4696 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9709 - val_f1score: 0.0000e+00\n",
      "Epoch 21/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 278.0717 - accuracy: 0.9983 - precision: 0.9986 - recall: 0.9979 - auc: 1.0000 - f1score: 0.9983 - val_loss: 281.9901 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9766 - val_f1score: 0.0000e+00\n",
      "Epoch 22/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 271.7045 - accuracy: 0.9966 - precision: 0.9952 - recall: 0.9979 - auc: 0.9999 - f1score: 0.9966 - val_loss: 276.0313 - val_accuracy: 0.9521 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9679 - val_f1score: 0.0000e+00\n",
      "Epoch 23/100\n",
      "92/92 [==============================] - 109s 1s/step - loss: 265.6136 - accuracy: 0.9990 - precision: 0.9986 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9990 - val_loss: 270.3235 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9779 - val_f1score: 0.0000e+00\n",
      "Epoch 24/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 259.8388 - accuracy: 0.9877 - precision: 0.9837 - recall: 0.9918 - auc: 0.9986 - f1score: 0.9877 - val_loss: 264.7906 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9779 - val_f1score: 0.0000e+00\n",
      "Epoch 25/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 254.2134 - accuracy: 0.9966 - precision: 0.9959 - recall: 0.9973 - auc: 0.9999 - f1score: 0.9966 - val_loss: 259.3450 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9769 - val_f1score: 0.0000e+00\n",
      "Epoch 26/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 248.8995 - accuracy: 0.9976 - precision: 0.9959 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9976 - val_loss: 254.1799 - val_accuracy: 0.9589 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9689 - val_f1score: 0.0000e+00\n",
      "Epoch 27/100\n",
      "92/92 [==============================] - 107s 1s/step - loss: 243.6250 - accuracy: 0.9986 - precision: 0.9973 - recall: 1.0000 - auc: 1.0000 - f1score: 0.9986 - val_loss: 249.2581 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9779 - val_f1score: 0.0000e+00\n",
      "Epoch 28/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 238.7518 - accuracy: 0.9986 - precision: 0.9979 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9986 - val_loss: 244.6373 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9764 - val_f1score: 0.0000e+00\n",
      "Epoch 29/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 233.9891 - accuracy: 0.9819 - precision: 0.9796 - recall: 0.9843 - auc: 0.9979 - f1score: 0.9819 - val_loss: 240.1446 - val_accuracy: 0.9315 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9596 - val_f1score: 0.0000e+00\n",
      "Epoch 30/100\n",
      "92/92 [==============================] - 107s 1s/step - loss: 229.2726 - accuracy: 0.9884 - precision: 0.9844 - recall: 0.9925 - auc: 0.9994 - f1score: 0.9884 - val_loss: 235.7520 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9704 - val_f1score: 0.0000e+00\n",
      "Epoch 31/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 224.7227 - accuracy: 0.9976 - precision: 0.9952 - recall: 1.0000 - auc: 1.0000 - f1score: 0.9976 - val_loss: 231.1433 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9705 - val_f1score: 0.0000e+00\n",
      "Epoch 32/100\n",
      "92/92 [==============================] - 107s 1s/step - loss: 220.4024 - accuracy: 0.9904 - precision: 0.9904 - recall: 0.9904 - auc: 0.9992 - f1score: 0.9904 - val_loss: 227.3258 - val_accuracy: 0.8836 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9272 - val_f1score: 0.0000e+00\n",
      "Epoch 33/100\n",
      "92/92 [==============================] - 107s 1s/step - loss: 216.1235 - accuracy: 0.9938 - precision: 0.9918 - recall: 0.9959 - auc: 0.9998 - f1score: 0.9939 - val_loss: 223.0588 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9773 - val_f1score: 0.0000e+00\n",
      "Epoch 34/100\n",
      "92/92 [==============================] - 107s 1s/step - loss: 212.0448 - accuracy: 0.9986 - precision: 0.9979 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9986 - val_loss: 218.7373 - val_accuracy: 0.9589 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9682 - val_f1score: 0.0000e+00\n",
      "Epoch 35/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 207.9534 - accuracy: 0.9993 - precision: 0.9993 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9993 - val_loss: 214.9637 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9778 - val_f1score: 0.0000e+00\n",
      "Epoch 36/100\n",
      "92/92 [==============================] - 107s 1s/step - loss: 204.0438 - accuracy: 0.9993 - precision: 0.9993 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9993 - val_loss: 211.2479 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9784 - val_f1score: 0.0000e+00\n",
      "Epoch 37/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 200.1010 - accuracy: 0.9990 - precision: 0.9986 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9990 - val_loss: 207.3138 - val_accuracy: 0.9589 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9759 - val_f1score: 0.0000e+00\n",
      "Epoch 38/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 196.2897 - accuracy: 0.9993 - precision: 0.9986 - recall: 1.0000 - auc: 1.0000 - f1score: 0.9993 - val_loss: 203.6955 - val_accuracy: 0.9521 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9587 - val_f1score: 0.0000e+00\n",
      "Epoch 39/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 192.7378 - accuracy: 0.9993 - precision: 0.9993 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9993 - val_loss: 200.0072 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9701 - val_f1score: 0.0000e+00\n",
      "Epoch 40/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 189.0727 - accuracy: 0.9986 - precision: 0.9979 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9986 - val_loss: 196.3965 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9778 - val_f1score: 0.0000e+00\n",
      "Epoch 41/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 185.4418 - accuracy: 0.9993 - precision: 0.9993 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9993 - val_loss: 193.3032 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9786 - val_f1score: 0.0000e+00\n",
      "Epoch 42/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 181.9630 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - f1score: 1.0000 - val_loss: 189.8190 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9702 - val_f1score: 0.0000e+00\n",
      "Epoch 43/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 178.6168 - accuracy: 0.9805 - precision: 0.9776 - recall: 0.9836 - auc: 0.9982 - f1score: 0.9806 - val_loss: 186.5215 - val_accuracy: 0.9521 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9545 - val_f1score: 0.0000e+00\n",
      "Epoch 44/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 175.2223 - accuracy: 0.9914 - precision: 0.9918 - recall: 0.9911 - auc: 0.9993 - f1score: 0.9914 - val_loss: 183.2369 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9783 - val_f1score: 0.0000e+00\n",
      "Epoch 45/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 171.9169 - accuracy: 0.9956 - precision: 0.9932 - recall: 0.9979 - auc: 0.9999 - f1score: 0.9956 - val_loss: 179.8787 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9713 - val_f1score: 0.0000e+00\n",
      "Epoch 46/100\n",
      "92/92 [==============================] - 106s 1s/step - loss: 168.7667 - accuracy: 0.9979 - precision: 0.9979 - recall: 0.9979 - auc: 1.0000 - f1score: 0.9979 - val_loss: 176.5499 - val_accuracy: 0.9589 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9777 - val_f1score: 0.0000e+00\n",
      "Epoch 47/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 165.4943 - accuracy: 0.9938 - precision: 0.9925 - recall: 0.9952 - auc: 0.9993 - f1score: 0.9938 - val_loss: 174.1733 - val_accuracy: 0.7397 - val_precision: 0.0270 - val_recall: 0.3333 - val_auc: 0.8086 - val_f1score: 0.0500\n",
      "Epoch 48/100\n",
      "92/92 [==============================] - 109s 1s/step - loss: 162.5262 - accuracy: 0.9959 - precision: 0.9945 - recall: 0.9973 - auc: 0.9999 - f1score: 0.9959 - val_loss: 170.4376 - val_accuracy: 0.9589 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9777 - val_f1score: 0.0000e+00\n",
      "Epoch 49/100\n",
      "92/92 [==============================] - 109s 1s/step - loss: 159.4231 - accuracy: 0.9846 - precision: 0.9843 - recall: 0.9849 - auc: 0.9983 - f1score: 0.9846 - val_loss: 168.4373 - val_accuracy: 0.7534 - val_precision: 0.0286 - val_recall: 0.3333 - val_auc: 0.8108 - val_f1score: 0.0526\n",
      "Epoch 50/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 156.5398 - accuracy: 0.9781 - precision: 0.9761 - recall: 0.9802 - auc: 0.9945 - f1score: 0.9781 - val_loss: 164.7434 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9784 - val_f1score: 0.0000e+00\n",
      "Epoch 51/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 153.5674 - accuracy: 0.9956 - precision: 0.9952 - recall: 0.9959 - auc: 0.9999 - f1score: 0.9956 - val_loss: 161.9637 - val_accuracy: 0.9384 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9625 - val_f1score: 0.0000e+00\n",
      "Epoch 52/100\n",
      "92/92 [==============================] - 109s 1s/step - loss: 150.6270 - accuracy: 0.9997 - precision: 0.9993 - recall: 1.0000 - auc: 1.0000 - f1score: 0.9997 - val_loss: 158.9443 - val_accuracy: 0.9589 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9768 - val_f1score: 0.0000e+00\n",
      "Epoch 53/100\n",
      "92/92 [==============================] - 109s 1s/step - loss: 147.7979 - accuracy: 0.9973 - precision: 0.9966 - recall: 0.9979 - auc: 1.0000 - f1score: 0.9973 - val_loss: 156.0013 - val_accuracy: 0.9589 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9687 - val_f1score: 0.0000e+00\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92/92 [==============================] - 111s 1s/step - loss: 145.0166 - accuracy: 0.9979 - precision: 0.9973 - recall: 0.9986 - auc: 1.0000 - f1score: 0.9979 - val_loss: 153.2623 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9783 - val_f1score: 0.0000e+00\n",
      "Epoch 55/100\n",
      "92/92 [==============================] - 112s 1s/step - loss: 142.3127 - accuracy: 0.9959 - precision: 0.9945 - recall: 0.9973 - auc: 0.9991 - f1score: 0.9959 - val_loss: 150.3672 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9771 - val_f1score: 0.0000e+00\n",
      "Epoch 56/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 139.6725 - accuracy: 0.9839 - precision: 0.9816 - recall: 0.9863 - auc: 0.9967 - f1score: 0.9840 - val_loss: 147.8169 - val_accuracy: 0.9795 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9787 - val_f1score: 0.0000e+00\n",
      "Epoch 57/100\n",
      "92/92 [==============================] - 112s 1s/step - loss: 136.9452 - accuracy: 0.9986 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - f1score: 0.9986 - val_loss: 145.0841 - val_accuracy: 0.9315 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9605 - val_f1score: 0.0000e+00\n",
      "Epoch 58/100\n",
      "92/92 [==============================] - 112s 1s/step - loss: 134.3806 - accuracy: 0.9983 - precision: 0.9973 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9983 - val_loss: 142.5906 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9700 - val_f1score: 0.0000e+00\n",
      "Epoch 59/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 131.7909 - accuracy: 0.9986 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - f1score: 0.9986 - val_loss: 140.0062 - val_accuracy: 0.9315 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9593 - val_f1score: 0.0000e+00\n",
      "Epoch 60/100\n",
      "92/92 [==============================] - 109s 1s/step - loss: 129.3063 - accuracy: 0.9976 - precision: 0.9959 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9976 - val_loss: 137.5520 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9697 - val_f1score: 0.0000e+00\n",
      "Epoch 61/100\n",
      "92/92 [==============================] - 112s 1s/step - loss: 126.7915 - accuracy: 0.9997 - precision: 0.9993 - recall: 1.0000 - auc: 1.0000 - f1score: 0.9997 - val_loss: 135.0374 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9687 - val_f1score: 0.0000e+00\n",
      "Epoch 62/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 124.3970 - accuracy: 0.9986 - precision: 0.9986 - recall: 0.9986 - auc: 1.0000 - f1score: 0.9986 - val_loss: 132.5090 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9699 - val_f1score: 0.0000e+00\n",
      "Epoch 63/100\n",
      "92/92 [==============================] - 107s 1s/step - loss: 121.9452 - accuracy: 0.9993 - precision: 0.9993 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9993 - val_loss: 130.0361 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9764 - val_f1score: 0.0000e+00\n",
      "Epoch 64/100\n",
      "92/92 [==============================] - 107s 1s/step - loss: 119.5760 - accuracy: 0.9938 - precision: 0.9932 - recall: 0.9945 - auc: 0.9995 - f1score: 0.9938 - val_loss: 127.7296 - val_accuracy: 0.9452 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9597 - val_f1score: 0.0000e+00\n",
      "Epoch 65/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 117.2765 - accuracy: 0.9979 - precision: 0.9966 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9979 - val_loss: 125.5308 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9785 - val_f1score: 0.0000e+00\n",
      "Epoch 66/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 115.0105 - accuracy: 0.9918 - precision: 0.9918 - recall: 0.9918 - auc: 0.9992 - f1score: 0.9918 - val_loss: 123.2557 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9790 - val_f1score: 0.0000e+00\n",
      "Epoch 67/100\n",
      "92/92 [==============================] - 109s 1s/step - loss: 112.7072 - accuracy: 0.9945 - precision: 0.9932 - recall: 0.9959 - auc: 0.9999 - f1score: 0.9945 - val_loss: 121.0835 - val_accuracy: 0.9452 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9578 - val_f1score: 0.0000e+00\n",
      "Epoch 68/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 110.5602 - accuracy: 0.9956 - precision: 0.9939 - recall: 0.9973 - auc: 0.9995 - f1score: 0.9956 - val_loss: 118.6611 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9719 - val_f1score: 0.0000e+00\n",
      "Epoch 69/100\n",
      "92/92 [==============================] - 108s 1s/step - loss: 108.3342 - accuracy: 0.9983 - precision: 0.9973 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9983 - val_loss: 116.5486 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9776 - val_f1score: 0.0000e+00\n",
      "Epoch 70/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 106.2199 - accuracy: 0.9962 - precision: 0.9952 - recall: 0.9973 - auc: 0.9996 - f1score: 0.9962 - val_loss: 114.4272 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9788 - val_f1score: 0.0000e+00\n",
      "Epoch 71/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 104.1912 - accuracy: 0.9979 - precision: 0.9966 - recall: 0.9993 - auc: 0.9999 - f1score: 0.9979 - val_loss: 112.1525 - val_accuracy: 0.9452 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9689 - val_f1score: 0.0000e+00\n",
      "Epoch 72/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 102.1269 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - f1score: 1.0000 - val_loss: 109.9943 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9782 - val_f1score: 0.0000e+00\n",
      "Epoch 73/100\n",
      "92/92 [==============================] - 112s 1s/step - loss: 100.0118 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - auc: 1.0000 - f1score: 1.0000 - val_loss: 108.0347 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9775 - val_f1score: 0.0000e+00\n",
      "Epoch 74/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 98.1986 - accuracy: 0.9692 - precision: 0.9666 - recall: 0.9719 - auc: 0.9932 - f1score: 0.9693 - val_loss: 106.3396 - val_accuracy: 0.9178 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9460 - val_f1score: 0.0000e+00\n",
      "Epoch 75/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 96.1934 - accuracy: 0.9959 - precision: 0.9945 - recall: 0.9973 - auc: 0.9999 - f1score: 0.9959 - val_loss: 104.0732 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9786 - val_f1score: 0.0000e+00\n",
      "Epoch 76/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 94.2393 - accuracy: 0.9993 - precision: 0.9993 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9993 - val_loss: 102.1024 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9782 - val_f1score: 0.0000e+00\n",
      "Epoch 77/100\n",
      "92/92 [==============================] - 112s 1s/step - loss: 92.4079 - accuracy: 0.9983 - precision: 0.9979 - recall: 0.9986 - auc: 1.0000 - f1score: 0.9983 - val_loss: 100.1687 - val_accuracy: 0.9521 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9763 - val_f1score: 0.0000e+00\n",
      "Epoch 78/100\n",
      "92/92 [==============================] - 115s 1s/step - loss: 90.5990 - accuracy: 0.9959 - precision: 0.9945 - recall: 0.9973 - auc: 0.9999 - f1score: 0.9959 - val_loss: 98.2915 - val_accuracy: 0.9452 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9678 - val_f1score: 0.0000e+00\n",
      "Epoch 79/100\n",
      "92/92 [==============================] - 117s 1s/step - loss: 88.7573 - accuracy: 0.9983 - precision: 0.9973 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9983 - val_loss: 96.5852 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9788 - val_f1score: 0.0000e+00\n",
      "Epoch 80/100\n",
      "92/92 [==============================] - 113s 1s/step - loss: 87.0158 - accuracy: 0.9969 - precision: 0.9959 - recall: 0.9979 - auc: 0.9999 - f1score: 0.9969 - val_loss: 94.7077 - val_accuracy: 0.9452 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9687 - val_f1score: 0.0000e+00\n",
      "Epoch 81/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 85.1907 - accuracy: 0.9990 - precision: 0.9980 - recall: 1.0000 - auc: 1.0000 - f1score: 0.9990 - val_loss: 92.8922 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9780 - val_f1score: 0.0000e+00\n",
      "Epoch 82/100\n",
      "92/92 [==============================] - 109s 1s/step - loss: 83.5333 - accuracy: 0.9956 - precision: 0.9952 - recall: 0.9959 - auc: 0.9995 - f1score: 0.9956 - val_loss: 91.2353 - val_accuracy: 0.9178 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9529 - val_f1score: 0.0000e+00\n",
      "Epoch 83/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 81.8264 - accuracy: 0.9921 - precision: 0.9898 - recall: 0.9945 - auc: 0.9998 - f1score: 0.9921 - val_loss: 89.2626 - val_accuracy: 0.9452 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9622 - val_f1score: 0.0000e+00\n",
      "Epoch 84/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 80.1585 - accuracy: 0.9986 - precision: 0.9979 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9986 - val_loss: 87.5572 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9711 - val_f1score: 0.0000e+00\n",
      "Epoch 85/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 78.5081 - accuracy: 0.9962 - precision: 0.9952 - recall: 0.9973 - auc: 0.9999 - f1score: 0.9962 - val_loss: 85.8482 - val_accuracy: 0.9315 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9641 - val_f1score: 0.0000e+00\n",
      "Epoch 86/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 76.9380 - accuracy: 0.9873 - precision: 0.9870 - recall: 0.9877 - auc: 0.9986 - f1score: 0.9873 - val_loss: 84.2408 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9835 - val_f1score: 0.0000e+00\n",
      "Epoch 87/100\n",
      "92/92 [==============================] - 113s 1s/step - loss: 75.3774 - accuracy: 0.9945 - precision: 0.9918 - recall: 0.9973 - auc: 0.9991 - f1score: 0.9945 - val_loss: 82.7619 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9791 - val_f1score: 0.0000e+00\n",
      "Epoch 88/100\n",
      "92/92 [==============================] - 124s 1s/step - loss: 73.8190 - accuracy: 0.9925 - precision: 0.9911 - recall: 0.9938 - auc: 0.9998 - f1score: 0.9925 - val_loss: 81.2159 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9778 - val_f1score: 0.0000e+00\n",
      "Epoch 89/100\n",
      "92/92 [==============================] - 123s 1s/step - loss: 72.3269 - accuracy: 0.9993 - precision: 0.9986 - recall: 1.0000 - auc: 1.0000 - f1score: 0.9993 - val_loss: 79.4530 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9780 - val_f1score: 0.0000e+00\n",
      "Epoch 90/100\n",
      "92/92 [==============================] - 113s 1s/step - loss: 70.8735 - accuracy: 0.9846 - precision: 0.9849 - recall: 0.9843 - auc: 0.9988 - f1score: 0.9846 - val_loss: 78.1572 - val_accuracy: 0.9178 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9636 - val_f1score: 0.0000e+00\n",
      "Epoch 91/100\n",
      "92/92 [==============================] - 112s 1s/step - loss: 69.4371 - accuracy: 0.9976 - precision: 0.9959 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9976 - val_loss: 76.5021 - val_accuracy: 0.9726 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9771 - val_f1score: 0.0000e+00\n",
      "Epoch 92/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 67.9788 - accuracy: 0.9993 - precision: 0.9986 - recall: 1.0000 - auc: 1.0000 - f1score: 0.9993 - val_loss: 75.0294 - val_accuracy: 0.9452 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9765 - val_f1score: 0.0000e+00\n",
      "Epoch 93/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 66.6438 - accuracy: 0.9993 - precision: 0.9993 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9993 - val_loss: 73.4933 - val_accuracy: 0.9521 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9767 - val_f1score: 0.0000e+00\n",
      "Epoch 94/100\n",
      "92/92 [==============================] - 118s 1s/step - loss: 65.2348 - accuracy: 0.9997 - precision: 0.9993 - recall: 1.0000 - auc: 1.0000 - f1score: 0.9997 - val_loss: 72.1333 - val_accuracy: 0.9521 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9685 - val_f1score: 0.0000e+00\n",
      "Epoch 95/100\n",
      "92/92 [==============================] - 117s 1s/step - loss: 63.9416 - accuracy: 0.9884 - precision: 0.9877 - recall: 0.9890 - auc: 0.9974 - f1score: 0.9884 - val_loss: 70.8405 - val_accuracy: 0.9110 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9438 - val_f1score: 0.0000e+00\n",
      "Epoch 96/100\n",
      "92/92 [==============================] - 115s 1s/step - loss: 62.5382 - accuracy: 0.9966 - precision: 0.9959 - recall: 0.9973 - auc: 0.9999 - f1score: 0.9966 - val_loss: 69.3225 - val_accuracy: 0.9521 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9693 - val_f1score: 0.0000e+00\n",
      "Epoch 97/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 61.2658 - accuracy: 0.9986 - precision: 0.9979 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9986 - val_loss: 68.0741 - val_accuracy: 0.9521 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9679 - val_f1score: 0.0000e+00\n",
      "Epoch 98/100\n",
      "92/92 [==============================] - 109s 1s/step - loss: 59.9668 - accuracy: 0.9986 - precision: 0.9979 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9986 - val_loss: 66.6342 - val_accuracy: 0.9589 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9690 - val_f1score: 0.0000e+00\n",
      "Epoch 99/100\n",
      "92/92 [==============================] - 111s 1s/step - loss: 58.7745 - accuracy: 0.9908 - precision: 0.9898 - recall: 0.9918 - auc: 0.9986 - f1score: 0.9908 - val_loss: 65.4741 - val_accuracy: 0.9041 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9447 - val_f1score: 0.0000e+00\n",
      "Epoch 100/100\n",
      "92/92 [==============================] - 110s 1s/step - loss: 57.5233 - accuracy: 0.9986 - precision: 0.9979 - recall: 0.9993 - auc: 1.0000 - f1score: 0.9986 - val_loss: 64.0315 - val_accuracy: 0.9658 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.9705 - val_f1score: 0.0000e+00\n",
      "WARNING:tensorflow:From <ipython-input-1-e85146fdaed7>:146: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "6/6 [==============================] - 5s 808ms/step - loss: 65.7506 - accuracy: 0.9505 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.9804 - f1score: 0.0000e+00\n",
      "loss  =  65.75064086914062\n",
      "accuracy  =  0.9505494236946106\n",
      "precision  =  0.0\n",
      "recall  =  0.0\n",
      "auc  =  0.9804069995880127\n",
      "f1score  =  0.0\n",
      "WARNING:tensorflow:From <ipython-input-1-e85146fdaed7>:290: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "True (-)ves:  173 \n",
      "False (+)ves:  5 \n",
      "False (-)ves:  4 \n",
      "True (+)ves:  0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metric_preference' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e85146fdaed7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[0mcfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myaml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\PaulDS3\\\\Downloads\\\\project\\\\covid_cxr\\\\config.yml\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m     \u001b[0mtrain_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TRAIN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'EXPERIMENT_TYPE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_logs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1-e85146fdaed7>\u001b[0m in \u001b[0;36mtrain_experiment\u001b[1;34m(cfg, experiment, save_weights, write_logs)\u001b[0m\n\u001b[0;32m    373\u001b[0m                 \u001b[0mlog_test_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_metrics\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m             \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PATHS'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'MODEL_WEIGHTS'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'model'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmetric_preference\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcur_date\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m             \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Save the model's weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'metric_preference' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "import dill\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.summary as tf_summary\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from math import ceil\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, CategoricalAccuracy, Precision, Recall, AUC\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "from models.models import *\n",
    "from visualization.visualize import *\n",
    "from custom.metrics import F1Score\n",
    "from preprocess import remove_text\n",
    "from pathlib import Path\n",
    "\n",
    "def get_class_weights(histogram, class_multiplier=None):\n",
    "    '''\n",
    "    Computes weights for each class to be applied in the loss function during training.\n",
    "    :param histogram: A list depicting the number of each item in different class\n",
    "    :param class_multiplier: List of values to multiply the calculated class weights by. For further control of class weighting.\n",
    "    :return: A dictionary containing weights for each class\n",
    "    '''\n",
    "    weights = [None] * len(histogram)\n",
    "    for i in range(len(histogram)):\n",
    "        weights[i] = (1.0 / len(histogram)) * sum(histogram) / histogram[i]\n",
    "    class_weight = {i: weights[i] for i in range(len(histogram))}\n",
    "    if class_multiplier is not None:\n",
    "        class_weight = {i: class_weight[i] * class_multiplier[i] for i in range(len(histogram))} # changed from list to dict by addin '{i: }'\n",
    "    print(\"Class weights: \", class_weight)\n",
    "    return class_weight\n",
    "\n",
    "\n",
    "def random_minority_oversample(train_set):\n",
    "    '''\n",
    "    Oversample the minority class using the specified algorithm\n",
    "    :param train_set: Training set image file names and labels\n",
    "    :return: A new training set containing oversampled examples\n",
    "    '''\n",
    "    X_train = train_set[[x for x in train_set.columns if x != 'label']].to_numpy()\n",
    "    if X_train.shape[1] == 1:\n",
    "        X_train = np.expand_dims(X_train, axis=-1)\n",
    "    Y_train = train_set['label'].to_numpy()\n",
    "    sampler = RandomOverSampler(random_state=np.random.randint(0, high=1000))\n",
    "    X_resampled, Y_resampled = sampler.fit_resample(X_train, Y_train)\n",
    "    filenames = X_resampled[:, 1]     # Filename is in second column\n",
    "    label_strs = X_resampled[:, 2]    # Class name is in second column\n",
    "    print(\"Train set shape before oversampling: \", X_train.shape, \" Train set shape after resampling: \", X_resampled.shape)\n",
    "    train_set_resampled = pd.DataFrame({'filename': filenames, 'label': Y_resampled, 'label_str': label_strs})\n",
    "    return train_set_resampled\n",
    "\n",
    "\n",
    "def train_model(cfg, data, callbacks, verbose=1):\n",
    "    '''\n",
    "    Train a and evaluate model on given data.\n",
    "    :param cfg: Project config (from config.yml)\n",
    "    :param data: dict of partitioned dataset\n",
    "    :param callbacks: list of callbacks for Keras model\n",
    "    :param verbose: Verbosity mode to pass to model.fit_generator()\n",
    "    :return: Trained model and associated performance metrics on the test set\n",
    "    '''\n",
    "\n",
    "    # If set in config file, oversample the minority class\n",
    "    if cfg['TRAIN']['IMB_STRATEGY'] == 'random_oversample':\n",
    "        data['TRAIN'] = random_minority_oversample(data['TRAIN'])\n",
    "\n",
    "    # Create ImageDataGenerators\n",
    "    train_img_gen = ImageDataGenerator(rotation_range=10, preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "    val_img_gen = ImageDataGenerator(preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "    test_img_gen = ImageDataGenerator(preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "\n",
    "    # Create DataFrameIterators\n",
    "    raw_data = Path('C:/Users/PaulDS3/Downloads/project/covid_cxr/data/') # replace cfg['PATHS']['RAW_DATA']\n",
    "    out_class_ind = Path('C:/Users/PaulDS3/Downloads/project/covid_cxr/interpretability/output_class_indices.pkl') # replace cfg['PATHS']['OUTPUT_CLASS_INDICES']\n",
    "    img_shape = tuple(cfg['DATA']['IMG_DIM'])\n",
    "    y_col = 'label_str'\n",
    "    class_mode = 'categorical'\n",
    "    train_generator = train_img_gen.flow_from_dataframe(dataframe=data['TRAIN'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col=y_col, target_size=img_shape, batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "        class_mode=class_mode, validate_filenames=False)\n",
    "    val_generator = val_img_gen.flow_from_dataframe(dataframe=data['VAL'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col=y_col, target_size=img_shape, batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "        class_mode=class_mode, validate_filenames=False)\n",
    "    test_generator = test_img_gen.flow_from_dataframe(dataframe=data['TEST'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col=y_col, target_size=img_shape, batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "        class_mode=class_mode, validate_filenames=False, shuffle=False)\n",
    "\n",
    "    # Save model's ordering of class indices\n",
    "    dill.dump(test_generator.class_indices, open(out_class_ind, 'wb')) # replaced cfg['PATHS']['OUTPUT_CLASS_INDICES']\n",
    "    # Apply class imbalance strategy. We have many more X-rays negative for COVID-19 than positive.\n",
    "    histogram = np.bincount(np.array(train_generator.labels).astype(int))  # Get class distribution\n",
    "    class_weight = None\n",
    "    if cfg['TRAIN']['IMB_STRATEGY'] == 'class_weight':\n",
    "        class_multiplier = cfg['TRAIN']['CLASS_MULTIPLIER']\n",
    "        class_multiplier = [class_multiplier[cfg['DATA']['CLASSES'].index(c)] for c in test_generator.class_indices]\n",
    "        class_weight = get_class_weights(histogram, class_multiplier)\n",
    "\n",
    "    # Define metrics.\n",
    "    covid_class_idx = test_generator.class_indices['COVID-19']   # Get index of COVID-19 class\n",
    "    thresholds = 1.0 / len(cfg['DATA']['CLASSES'])      # Binary classification threshold for a class\n",
    "    metrics = [CategoricalAccuracy(name='accuracy'),\n",
    "               Precision(name='precision', thresholds=thresholds, class_id=covid_class_idx),\n",
    "               Recall(name='recall', thresholds=thresholds, class_id=covid_class_idx),\n",
    "               AUC(name='auc'),\n",
    "               F1Score(name='f1score', thresholds=thresholds, class_id=covid_class_idx)]\n",
    "\n",
    "    # Define the model.\n",
    "    print('Training distribution: ', ['Class ' + list(test_generator.class_indices.keys())[i] + ': ' + str(histogram[i]) + '. '\n",
    "           for i in range(len(histogram))])\n",
    "    input_shape = cfg['DATA']['IMG_DIM'] + [3]\n",
    "    num_gpus = cfg['TRAIN']['NUM_GPUS']\n",
    "    if cfg['TRAIN']['MODEL_DEF'] == 'dcnn_resnet':\n",
    "        model_def = dcnn_resnet\n",
    "    elif cfg['TRAIN']['MODEL_DEF'] == 'resnet50v2':\n",
    "        model_def = resnet50v2\n",
    "    else:\n",
    "        model_def = resnet101v2\n",
    "    if cfg['TRAIN']['CLASS_MODE'] == 'binary':\n",
    "        histogram = np.bincount(data['TRAIN']['label'].astype(int))\n",
    "        output_bias = np.log([histogram[i] / (np.sum(histogram) - histogram[i]) for i in range(histogram.shape[0])])\n",
    "        model = model_def(cfg['NN']['DCNN_BINARY'], input_shape, metrics, 2, output_bias=output_bias, gpus=num_gpus) #removed gpus=num_gpus\n",
    "    else:\n",
    "        n_classes = len(cfg['DATA']['CLASSES'])\n",
    "        histogram = np.bincount(data['TRAIN']['label'].astype(int))\n",
    "        output_bias = np.log([histogram[i] / (np.sum(histogram) - histogram[i]) for i in range(histogram.shape[0])])\n",
    "        model = model_def(cfg['NN']['DCNN_MULTICLASS'], input_shape, metrics, n_classes, output_bias=output_bias, gpus=num_gpus) #removed gpus=num_gpus\n",
    "\n",
    "    # Train the model.\n",
    "    steps_per_epoch = ceil(train_generator.n / train_generator.batch_size)\n",
    "    val_steps = ceil(val_generator.n / val_generator.batch_size)\n",
    "    # changed model.fit_generator to model.fit()\n",
    "    history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=cfg['TRAIN']['EPOCHS'],\n",
    "                                  validation_data=val_generator, validation_steps=val_steps, callbacks=callbacks,\n",
    "                                  verbose=verbose, class_weight=class_weight)\n",
    "\n",
    "    # Run the model on the test set and print the resulting performance metrics.\n",
    "    test_results = model.evaluate_generator(test_generator, verbose=1)\n",
    "    test_metrics = {}\n",
    "    test_summary_str = [['**Metric**', '**Value**']]\n",
    "    for metric, value in zip(model.metrics_names, test_results):\n",
    "        test_metrics[metric] = value\n",
    "        print(metric, ' = ', value)\n",
    "        test_summary_str.append([metric, str(value)])\n",
    "    return model, test_metrics, test_generator\n",
    "\n",
    "\n",
    "def multi_train(cfg, data, callbacks, base_log_dir):\n",
    "    '''\n",
    "    Trains a model a series of times and returns the model with the best test set metric (specified in cfg)\n",
    "    :param cfg: Project config (from config.yml)\n",
    "    :param data: Partitioned dataset\n",
    "    :param callbacks: List of callbacks to pass to model.fit()\n",
    "    :param base_log_dir: Base directory to write logs\n",
    "    :return: The trained Keras model with best test set performance on the metric specified in cfg\n",
    "    '''\n",
    "\n",
    "    # Load order of metric preference\n",
    "    metric_preference = cfg['TRAIN']['METRIC_PREFERENCE']\n",
    "    best_metrics = dict.fromkeys(metric_preference, 0.0)\n",
    "    if 'loss' in metric_preference:\n",
    "        best_metrics['loss'] = 100000.0\n",
    "\n",
    "    # Train NUM_RUNS models and return the best one according to the preferred metrics\n",
    "    for i in range(cfg['TRAIN']['NUM_RUNS']):\n",
    "        print(\"Training run \", i+1, \" / \", cfg['TRAIN']['NUM_RUNS'])\n",
    "        cur_callbacks = callbacks.copy()\n",
    "        cur_date = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "        if base_log_dir is not None:\n",
    "            log_dir = base_log_dir + cur_date\n",
    "            cur_callbacks.append(TensorBoard(log_dir=log_dir, histogram_freq=1))\n",
    "\n",
    "        # Train the model and evaluate performance on test set\n",
    "        new_model, test_metrics, test_generator = train_model(cfg, data, cur_callbacks, verbose=1)\n",
    "\n",
    "        # Log test set results and images\n",
    "        if base_log_dir is not None:\n",
    "            log_test_results(cfg, new_model, test_generator, test_metrics, log_dir)\n",
    "\n",
    "        # If this model outperforms the previous ones based on the specified metric preferences, save this one.\n",
    "        for i in range(len(metric_preference)):\n",
    "            if (((metric_preference[i] == 'loss') and (test_metrics[metric_preference[i]] < best_metrics[metric_preference[i]]))\n",
    "                    or ((metric_preference[i] != 'loss') and (test_metrics[metric_preference[i]] > best_metrics[metric_preference[i]]))):\n",
    "                best_model = new_model\n",
    "                best_metrics = test_metrics\n",
    "                best_generator = test_generator\n",
    "                best_model_date = cur_date\n",
    "                break\n",
    "            elif (test_metrics[metric_preference[i]] == best_metrics[metric_preference[i]]):\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    print(\"Best model test metrics: \", best_metrics)\n",
    "    return best_model, best_metrics, best_generator, best_model_date\n",
    "\n",
    "\n",
    "def random_hparam_search(cfg, data, callbacks, log_dir):\n",
    "    '''\n",
    "    Conduct a random hyperparameter search over the ranges given for the hyperparameters in config.yml and log results\n",
    "    in TensorBoard. Model is trained x times for y random combinations of hyperparameters.\n",
    "    :param cfg: Project config\n",
    "    :param data: Dict containing the partitioned datasets\n",
    "    :param callbacks: List of callbacks for Keras model (excluding TensorBoard)\n",
    "    :param log_dir: Base directory in which to store logs\n",
    "    :return: (Last model trained, resultant test set metrics, test data generator)\n",
    "    '''\n",
    "\n",
    "    # Define HParam objects for each hyperparameter we wish to tune.\n",
    "    hp_ranges = cfg['HP_SEARCH']['RANGES']\n",
    "    HPARAMS = []\n",
    "    HPARAMS.append(hp.HParam('KERNEL_SIZE', hp.Discrete(hp_ranges['KERNEL_SIZE'])))\n",
    "    HPARAMS.append(hp.HParam('MAXPOOL_SIZE', hp.Discrete(hp_ranges['MAXPOOL_SIZE'])))\n",
    "    HPARAMS.append(hp.HParam('INIT_FILTERS', hp.Discrete(hp_ranges['INIT_FILTERS'])))\n",
    "    HPARAMS.append(hp.HParam('FILTER_EXP_BASE', hp.IntInterval(hp_ranges['FILTER_EXP_BASE'][0], hp_ranges['FILTER_EXP_BASE'][1])))\n",
    "    HPARAMS.append(hp.HParam('NODES_DENSE0', hp.Discrete(hp_ranges['NODES_DENSE0'])))\n",
    "    HPARAMS.append(hp.HParam('CONV_BLOCKS', hp.IntInterval(hp_ranges['CONV_BLOCKS'][0], hp_ranges['CONV_BLOCKS'][1])))\n",
    "    HPARAMS.append(hp.HParam('DROPOUT', hp.Discrete(hp_ranges['DROPOUT'])))\n",
    "    HPARAMS.append(hp.HParam('LR', hp.RealInterval(hp_ranges['LR'][0], hp_ranges['LR'][1])))\n",
    "    HPARAMS.append(hp.HParam('OPTIMIZER', hp.Discrete(hp_ranges['OPTIMIZER'])))\n",
    "    HPARAMS.append(hp.HParam('L2_LAMBDA', hp.Discrete(hp_ranges['L2_LAMBDA'])))\n",
    "    HPARAMS.append(hp.HParam('BATCH_SIZE', hp.Discrete(hp_ranges['BATCH_SIZE'])))\n",
    "    HPARAMS.append(hp.HParam('IMB_STRATEGY', hp.Discrete(hp_ranges['IMB_STRATEGY'])))\n",
    "\n",
    "    # Define test set metrics that we wish to log to TensorBoard for each training run\n",
    "    HP_METRICS = [hp.Metric(metric, display_name='Test ' + metric) for metric in cfg['HP_SEARCH']['METRICS']]\n",
    "\n",
    "    # Configure TensorBoard to log the results\n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams_config(hparams=HPARAMS, metrics=HP_METRICS)\n",
    "\n",
    "    # Complete a number of training runs at different hparam values and log the results.\n",
    "    repeats_per_combo = cfg['HP_SEARCH']['REPEATS']   # Number of times to train the model per combination of hparams\n",
    "    num_combos = cfg['HP_SEARCH']['COMBINATIONS']     # Number of random combinations of hparams to attempt\n",
    "    num_sessions = num_combos * repeats_per_combo       # Total number of runs in this experiment\n",
    "    model_type = 'DCNN_BINARY' if cfg['TRAIN']['CLASS_MODE'] == 'binary' else 'DCNN_MULTICLASS'\n",
    "    trial_id = 0\n",
    "    for group_idx in range(num_combos):\n",
    "        rand = random.Random()\n",
    "        HPARAMS = {h: h.domain.sample_uniform(rand) for h in HPARAMS}\n",
    "        hparams = {h.name: HPARAMS[h] for h in HPARAMS}  # To pass to model definition\n",
    "        for repeat_idx in range(repeats_per_combo):\n",
    "            trial_id += 1\n",
    "            print(\"Running training session %d/%d\" % (trial_id, num_sessions))\n",
    "            print(\"Hparam values: \", {h.name: HPARAMS[h] for h in HPARAMS})\n",
    "            trial_logdir = os.path.join(log_dir, str(trial_id))     # Need specific logdir for each trial\n",
    "            callbacks_hp = callbacks + [TensorBoard(log_dir=trial_logdir, profile_batch=0, write_graph=False)]\n",
    "\n",
    "            # Set values of hyperparameters for this run in config file.\n",
    "            for h in hparams:\n",
    "                if h in ['LR', 'L2_LAMBDA']:\n",
    "                    val = 10 ** hparams[h]      # These hyperparameters are sampled on the log scale.\n",
    "                else:\n",
    "                    val = hparams[h]\n",
    "                cfg['NN'][model_type][h] = val\n",
    "\n",
    "            # Set some hyperparameters that are not specified in model definition.\n",
    "            cfg['TRAIN']['BATCH_SIZE'] = hparams['BATCH_SIZE']\n",
    "            cfg['TRAIN']['IMB_STRATEGY'] = hparams['IMB_STRATEGY']\n",
    "\n",
    "            # Run a training session and log the performance metrics on the test set to HParams dashboard in TensorBoard\n",
    "            with tf.summary.create_file_writer(trial_logdir).as_default():\n",
    "                hp.hparams(HPARAMS, trial_id=str(trial_id))\n",
    "                model, test_metrics, test_generator = train_model(cfg, data, callbacks_hp, verbose=0)\n",
    "                for metric in HP_METRICS:\n",
    "                    if metric._tag in test_metrics:\n",
    "                        tf.summary.scalar(metric._tag, test_metrics[metric._tag], step=1)   # Log test metric\n",
    "    return\n",
    "\n",
    "\n",
    "def log_test_results(cfg, model, test_generator, test_metrics, log_dir):\n",
    "    '''\n",
    "    Visualize performance of a trained model on the test set. Optionally save the model.\n",
    "    :param cfg: Project config\n",
    "    :param model: A trained Keras model\n",
    "    :param test_generator: A Keras generator for the test set\n",
    "    :param test_metrics: Dict of test set performance metrics\n",
    "    :param log_dir: Path to write TensorBoard logs\n",
    "    '''\n",
    "\n",
    "    # Visualization of test results\n",
    "    test_predictions = model.predict_generator(test_generator, verbose=0)\n",
    "    test_labels = test_generator.labels\n",
    "    covid_idx = test_generator.class_indices['COVID-19']\n",
    "    plt = plot_roc(\"Test set\", test_labels, test_predictions, class_id=covid_idx)\n",
    "    roc_img = plot_to_tensor()\n",
    "    plt = plot_confusion_matrix(test_labels, test_predictions, class_id=covid_idx)\n",
    "    cm_img = plot_to_tensor()\n",
    "\n",
    "    # Log test set results and plots in TensorBoard\n",
    "    writer = tf_summary.create_file_writer(logdir=log_dir)\n",
    "\n",
    "    # Create table of test set metrics\n",
    "    test_summary_str = [['**Metric**','**Value**']]\n",
    "    thresholds = cfg['TRAIN']['THRESHOLDS']  # Load classification thresholds\n",
    "    for metric in test_metrics:\n",
    "        if metric in ['precision', 'recall'] and isinstance(metric, list):\n",
    "            metric_values = dict(zip(thresholds, test_metrics[metric]))\n",
    "        else:\n",
    "            metric_values = test_metrics[metric]\n",
    "        test_summary_str.append([metric, str(metric_values)])\n",
    "\n",
    "    # Create table of model and train config values\n",
    "    hparam_summary_str = [['**Variable**', '**Value**']]\n",
    "    for key in cfg['TRAIN']:\n",
    "        hparam_summary_str.append([key, str(cfg['TRAIN'][key])])\n",
    "    if cfg['TRAIN']['CLASS_MODE'] == 'binary':\n",
    "        for key in cfg['NN']['DCNN_BINARY']:\n",
    "            hparam_summary_str.append([key, str(cfg['NN']['DCNN_BINARY'][key])])\n",
    "    else:\n",
    "        for key in cfg['NN']['DCNN_BINARY']:\n",
    "            hparam_summary_str.append([key, str(cfg['NN']['DCNN_BINARY'][key])])\n",
    "\n",
    "    # Write to TensorBoard logs\n",
    "    with writer.as_default():\n",
    "        tf_summary.text(name='Test set metrics', data=tf.convert_to_tensor(test_summary_str), step=0)\n",
    "        tf_summary.text(name='Run hyperparameters', data=tf.convert_to_tensor(hparam_summary_str), step=0)\n",
    "        tf_summary.image(name='ROC Curve (Test Set)', data=roc_img, step=0)\n",
    "        tf_summary.image(name='Confusion Matrix (Test Set)', data=cm_img, step=0)\n",
    "    return\n",
    "\n",
    "def train_experiment(cfg=None, experiment='single_train', save_weights=True, write_logs=True):\n",
    "    '''\n",
    "    Defines and trains HIFIS-v2 model. Prints and logs relevant metrics.\n",
    "    :param experiment: The type of training experiment. Choices are {'single_train'}\n",
    "    :param save_weights: A flag indicating whether to save the model weights\n",
    "    :param write_logs: A flag indicating whether to write TensorBoard logs\n",
    "    :return: A dictionary of metrics on the test set\n",
    "    '''\n",
    "\n",
    "    # Load project config data\n",
    "    if cfg is None:\n",
    "        cfg = yaml.full_load(open(\"C:\\\\Users\\\\PaulDS3\\\\Downloads\\\\project\\\\covid-cxr\\\\config.yml\", 'r'))\n",
    "        \n",
    "    metric_preference = cfg['TRAIN']['METRIC_PREFERENCE']\n",
    "    \n",
    "    # Set logs directory\n",
    "    cur_date = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    log_dir = cfg['PATHS']['LOGS'] + \"training\\\\\" + cur_date if write_logs else None\n",
    "    if not os.path.exists(cfg['PATHS']['LOGS'] + \"training\\\\\"):\n",
    "        os.makedirs(cfg['PATHS']['LOGS'] + \"training\\\\\")\n",
    "\n",
    "    # Load dataset file paths and labels\n",
    "    data = {}\n",
    "    data['TRAIN'] = pd.read_csv(cfg['PATHS']['TRAIN_SET'])\n",
    "    data['VAL'] = pd.read_csv(cfg['PATHS']['VAL_SET'])\n",
    "    data['TEST'] = pd.read_csv(cfg['PATHS']['TEST_SET'])\n",
    "\n",
    "    # Set callbacks.\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=cfg['TRAIN']['PATIENCE'], mode='min', restore_best_weights=True)\n",
    "    callbacks = [early_stopping]\n",
    "\n",
    "    # Conduct the desired train experiment\n",
    "    if experiment == 'hparam_search':\n",
    "        log_dir = cfg['PATHS']['LOGS'] + \"hparam_search\\\\\" + cur_date\n",
    "        random_hparam_search(cfg, data, callbacks, log_dir)\n",
    "    else:\n",
    "        if experiment == 'multi_train':\n",
    "            base_log_dir = cfg['PATHS']['LOGS'] + \"training\\\\\" if write_logs else None\n",
    "            model, test_metrics, test_generator, cur_date = multi_train(cfg, data, callbacks, base_log_dir)\n",
    "        else:\n",
    "            if write_logs:\n",
    "                tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                callbacks.append(tensorboard)\n",
    "            model, test_metrics, test_generator = train_model(cfg, data, callbacks)\n",
    "            if write_logs:\n",
    "                log_test_results(cfg, model, test_generator, test_metrics, log_dir)\n",
    "        if save_weights:\n",
    "            model_path = cfg['PATHS']['MODEL_WEIGHTS'] + 'model' + '_' + metric_preference[0] + '_' + cur_date + '.h5'\n",
    "            save_model(model, model_path)  # Save the model's weights\n",
    "    return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cfg = yaml.full_load(open(\"C:\\\\Users\\\\PaulDS3\\\\Downloads\\\\project\\\\covid_cxr\\\\config.yml\", 'r'))\n",
    "    train_experiment(cfg=cfg, experiment=cfg['TRAIN']['EXPERIMENT_TYPE'], save_weights=True, write_logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1f8a688cae5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
